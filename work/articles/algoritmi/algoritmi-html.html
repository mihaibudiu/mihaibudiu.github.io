<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//RO">

<!--Converted with LaTeX2HTML 2K.1beta (1.47)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Algoritmi</TITLE>
<META NAME="description" CONTENT="Algoritmi">
<META NAME="keywords" CONTENT="algoritmi-html">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-2">
<META NAME="Generator" CONTENT="LaTeX2HTML v2K.1beta">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="../articles.css">

</HEAD>
<body>

<P>
<H1 ALIGN="CENTER">Algoritmi</H1>
<P ALIGN="CENTER"><STRONG>Mihai Budiu -- mihaib+@cs.cmu.edu, <TT>http://www.cs.cmu.edu/~mihaib/</TT></STRONG></P>
<P ALIGN="CENTER"><STRONG>1 iunie 1997</STRONG></P>

<P>
<DL>
<DT><STRONG>Subiect:</STRONG></DT>
<DD>Noi direcþii în cercetãri legate de algoritmi
</DD>
<DT><STRONG>Cunoºtinþe necesare:</STRONG></DT>
<DD>Cunoºtinþe elementare despre
algoritmi, analizã matematicã elementarã, teoria grafurilor
</DD>
<DT><STRONG>Cuvinte cheie:</STRONG></DT>
<DD>algoritm, invariant, complexitate, aproximaþie,
aleator, on-line.
</DD>
</DL>

<P>
<BR>

<H2><A NAME="SECTION00010000000000000000">
Contents</A>
</H2>
<!--Table of Contents-->

<UL>
<LI><A NAME="tex2html30"
  HREF="algoritmi-html.html">Algoritmi; complexitate</A>
<UL>
<LI><A NAME="tex2html31"
  HREF="#SECTION00021000000000000000">Limbajul de descriere</A>
<LI><A NAME="tex2html32"
  HREF="#SECTION00022000000000000000">Instanþe ºi probleme</A>
<LI><A NAME="tex2html33"
  HREF="#SECTION00023000000000000000">Complexitate asimptoticã</A>
<LI><A NAME="tex2html34"
  HREF="#SECTION00024000000000000000">Complexitatea revizuitã</A>
<LI><A NAME="tex2html35"
  HREF="#SECTION00025000000000000000">Complexitatea unei probleme</A>
<LI><A NAME="tex2html36"
  HREF="#SECTION00026000000000000000">Clasa P; alte clase deterministe</A>
<LI><A NAME="tex2html37"
  HREF="#SECTION00027000000000000000">Clasa NP; algoritmi nedeterminiºti; NP-completitudine</A>
</UL>
<BR>
<LI><A NAME="tex2html38"
  HREF="#SECTION00030000000000000000">Algoritmi aproximativi</A>
<UL>
<LI><A NAME="tex2html39"
  HREF="#SECTION00031000000000000000">Optim ºi aproximare</A>
<LI><A NAME="tex2html40"
  HREF="#SECTION00032000000000000000">Problema rucsacului</A>
<LI><A NAME="tex2html41"
  HREF="#SECTION00033000000000000000">Performanþa absolutã; un rezultat negativ</A>
</UL>
<BR>
<LI><A NAME="tex2html42"
  HREF="#SECTION00040000000000000000">Algoritmi Monte Carlo</A>
<LI><A NAME="tex2html43"
  HREF="#SECTION00050000000000000000">Algoritmi Las Vegas</A>
<UL>
<LI><A NAME="tex2html44"
  HREF="#SECTION00051000000000000000">Rãdãcinile unui polinom</A>
<LI><A NAME="tex2html45"
  HREF="#SECTION00052000000000000000">Izomorfismul arborilor</A>
</UL>
<BR>
<LI><A NAME="tex2html46"
  HREF="#SECTION00060000000000000000">Algoritmi on-line</A>
<UL>
<LI><A NAME="tex2html47"
  HREF="#SECTION00061000000000000000">Problema schiorului</A>
</UL>
<BR>
<LI><A NAME="tex2html48"
  HREF="#SECTION00070000000000000000">Rezumat</A>
</UL>
<!--End of Table of Contents-->
<BR>
<BR>

<P>
În ultimii ani cercetarea în domeniul algoritmilor a apucat pe
niºte cãi extrem de interesante ºi foarte deosebite de cele
tradiþionale.  Unele dintre aceste cãi erau prefigurate de
descoperiri fãcute cu multã vreme în urmã, dar nu fuseserã urmate
sistematic.  Altele sunt de datã recentã.  Metodele noi încearcã
sã depãºeascã criza în care intraserã metodele de rezolvare a
anumitor clase de probleme (cum ar fi cele NP-complete), sau sã facã
faþã unor probleme de naturi diferitã: informaþie incompletã (de
exemplu cînd trebuie luate decizii fãrã a cunoaºte cererile
ulterioare), informaþie distribuitã (într-o reþea de
calculatoare), informaþie ascunsã (în criptografie), etc.  Acest
articol îºi propune sã ilustreze foarte sumar cîteva dintre noile
direcþii de acþiune.

<P>

<H1><A NAME="SECTION00020000000000000000">
Algoritmi; complexitate</A>
</H1>

<P>
În aceastã secþiune vom face o scurtã recapitulare a principalelor
noþiuni care ne sunt necesare în înþelegerea celorlalte pãrþi.
Acestea sunt bine-cunoscute din studiul algoritmilor clasici, astfel
încît cititorul informat le poate sãri fãrã pierderi de
informaþie.  Tratarea va fi desigur sumarã; cititorul ne-informat
este invitat sã parcurgã cãrþi clasice în domeniu pentru o
discuþie mai amplã.  Pe de altã parte aceste noþiuni nu sunt
simple, ºi foarte arar sunt tratate într-adevãr riguros.  Deºi
expunerea de faþã va fi sumarã, sper cã nu va pãcãtui ºi prin
lipsã de corectitudine.

<P>

<H2><A NAME="SECTION00021000000000000000">
Limbajul de descriere</A>
</H2>

<P>
Un algoritm este o descriere a unui proces de calcul, care din
niºte date iniþiale produce niºte rezultate interesante.
Descrierea se face în termenii unor <EM>operaþii elementare</EM>
(operaþii aritmetice, comparaþii, decizii, etc.).

<P>
Aparent modul în care rezolvãm problemele depinde de operaþiile pe
care le avem la-ndemînã.  În cazul acesta se iveºte natural
întrebarea dacã anumite operaþii nu sunt mai expresive decît
altele.  Acest lucru este adevãrat, dupã cum se vede ºi din
proliferarea limbajelor de programare; un astfel de limbaj defineºte
practic o colecþie de operaþii elementare.

<P>
Se poate demonstra absolut riguros, cã în oarecare mãsurã alegerea
limbajului este irelevantã, pentru cã, din momentul în care avem un
limbaj suficient de expresiv, putem simula cu ajutorul lui operaþiile
care se fac în toate celelalte limbaje cunoscute.  Astfel, toate
formalismele care exprimã procese de calcul au fost demonstrate ca
fiind echivalente ca putere expresivã (limbajele de programare,
lambda calculul, funcþiile recursive, gramaticile de tip 0, maºinile
Turing: toate aceste metode de calcul pînã la urmã sunt
echivalente).

<P>
Din acest motiv ne putem fixa asupra unui limbaj anume, fãrã a
pierde nimic din generalitatea expunerii.  Voi folosi pentru exemplele
din acest articol un limbaj foarte simplu, asemãnãtor cu limbajele
obiºnuite de programare.  Limbajul (``guarded command language'') a
fost introdus de Dijkstra, ºi se bazeazã pe folosirea <EM>gãrzilor</EM>, care sunt niºte simple expresii booleene.  Gãrzile sunt
folosite pentru a descrie douã construcþii: bucla <TT>do</TT> ºi
instrucþiunea <TT>if</TT>.  Astfel:

<P>
<PRE>
do garda_1 -&gt; instructiune_1
[] garda_2 -&gt; instructiune_2
...
[] garda_n -&gt; instructiune_n
od
</PRE>

<P>
funcþioneazã astfel: gãrzile se evalueazã; dacã:

<P>

<UL>
<LI>toate sunt false, atunci ciclul <TT>do</TT> se terminã.  
</LI>
<LI>dacã cel puþin o gardã este adevãratã, atunci instrucþiunea
corespunzãtoare se executã, dupã care bucla se reia.  
</LI>
<LI>în caz cã mai multe gãrzi sunt adevãrate, atunci una dintre
instrucþiuni se va executa, dar care, nu se ºtie.
</LI>
</UL>

<P>
Dacã programatorul vrea sã fie sigur ce instrucþiune se executã,
nu are decît sã construiascã programul în aºa fel încît douã
gãrzi sa nu fie adevãrate simultan.

<P>
Construcþia <TT>do</TT> este asemãnãtoare cu un <TT>while</TT> urmat de
un <TT>switch</TT> din C, dar este mai uºor de folosit.  Oricum, este
evident cã este la fel de expresivã.

<P>
Folosim apoi construcþia <TT>if</TT> pe post de <TT>switch</TT> (<TT>case</TT>
din Pascal):

<P>
<PRE>
if garda_1 -&gt; instructiune_1
[] garda_2 -&gt; instructiune_2
...
[] garda_n -&gt; instructiune_n
fi
</PRE>

<P>
Semnificaþia este foarte asemãnãtoare cu a lui <TT>do</TT>.  Astfel:

<P>

<UL>
<LI>Dacã nici o gardã nu este adevãratã programul se terminã
imediat (eroare);
</LI>
<LI>Dacã o gardã este adevãratã instrucþiunea corespunzãtoare
se executã;
</LI>
<LI>Cînd mai multe gãrzi sunt adevãrate, una dintre
instrucþiunile care le corespund este executatã, dar nu se
precizeazã care.
</LI>
</UL>

<P>
Mai folosim ºi atribuirea paralelã:

<P>
<PRE>
v_1, v_2, ..., v_n := e_1, e_2, ..., e_n
</PRE>

<P>
Prin care expresiile din dreapta sunt toate evaluate ºi atribuite
simultan variabilelor din stînga.  Din cauza asta schimbul valorilor
a douã variabile se poate face cu 

<P>
<PRE>
x, y := y, x
</PRE>

<P>
care operaþie nu este echivalentã nici cu 

<P>
<PRE>
x := y 
y := x
</PRE>

<P>
ºi nici cu

<P>
<PRE>
y := x
x := y
</PRE>

<P>

<H3><A NAME="SECTION00021100000000000000">
Un exemplu</A>
</H3>

<P>
Ca sã ne familiarizãm cu limbajul, sã scriem un mic algoritm, care,
dîndu-se o valoare <TT>x</TT> ºi un vector <TT>a</TT> cu <TT>n</TT> elemente,
partiþioneazã vectorul în aºa fel încît valorile mai mici ca
<TT>x</TT> ajung în stînga, cele mai mari în dreapta, iar toate cele
egale cu <TT>x</TT> sunt contigue, undeva între celelalte douã (acesta
este un fragment din quicksort):

<P>
<PRE>
l, r, m := 1, n, 1
do a[m] = x -&gt; m := m+1
[] a[m] &lt; x -&gt; a[l], a[m], l, m := a[m], a[l], l+1, m+1
[] (a[m] &gt; x) and (m &lt; r) -&gt; a[r], a[m], r := a[m], a[r], r-1
[] a[r] &gt; x -&gt; r := r-1
od
</PRE>

<P>
Acest algoritm opereazã asupra vectorului <TT>a</TT> menþinînd
urmãtorul <EM>invariant</EM> (o relaþie care este întotdeauna
adevãratã):

<P>
<PRE>
|     &lt;     |        =      |         ?       |      &gt;    | a
-----------------------------------------------------------
 1           ^               ^                 ^         n
             l               m                 r
</PRE>

<P>
Variabilele <TT>l</TT>, <TT>m</TT> ºi <TT>r</TT> sunt indici în vectorul <TT>a</TT>.  Tot ce e la stînga lui <TT>l</TT> e mai mic decît <TT>x</TT>, tot ce
este cuprins între <TT>l</TT> (inclusiv) ºi <TT>m</TT> (exclusiv) este
egal cu <TT>x</TT>, iar tot ce se aflã la dreapta lui <TT>r</TT> este mai
mare ca <TT>x</TT>.  Elementele dintre <TT>m</TT> ºi <TT>r</TT> sunt încã
ne-explorate.  Aceastã relaþie este adevãratã atunci cînd
algoritmul începe, din modul în care se iniþializeazã variabilele,
ºi rãmîne adevãratã la fiecare parcurgere a buclei <TT>do</TT>,
dupã cum se poate verifica.  Bucla se terminã cînd toate gãrzile
sunt adevãrate, ceea ce se poate doar dacã <TT>m = r</TT>, deci dacã
zona ne-exploratã s-a redus la 0.

<P>
Limbajul acesta nu este foarte eficace pentru a scrie sisteme de
operare, dar pentru a exprima algoritmi este foarte succint ºi
elegant.  Invariantul anterior se reduce, în cazul terminãrii, deci
cînd <TT>m = r</TT> la

<P>
<PRE>
|     &lt;          |        =         |      &gt;              | a
-----------------------------------------------------------
 1                ^                  ^                   n
                  l                  m=r
</PRE>

<P>
ceea ce implicã ºi corectitudinea algoritmului, pentru cã
acesta este rezultatul pe care trebuia sã-l obþinem.

<P>
Ca sã demonstrãm ca algoritmul se terminã întotdeauna, independent
de valorile lui <TT>x</TT>, <TT>n</TT> ºi <TT>a</TT>, observaþi cã ori toate
gãrzile sunt false (ºi atunci gata), ori cel puþin o gardã este
adevãratã, ºi atunci fie <TT>m</TT> creºte, fie <TT>r</TT> scade.  Cum
întotdeauna trebuie sã avem <TT>m &lt; r</TT>, bucla se poate parcurge de
cel mult <TT>n</TT> ori înainte de terminare.

<P>
Observaþi cã acest algoritm <EM>este</EM> nedeterminist, pentru cã
dacã <TT>a[r] &gt; x</TT> poate face douã alegeri.  Interesant este cã
rezultatul final nu depinde de care operaþie este fãcutã, pentru
cã ambele operaþii pãstreazã invariantul indicat ºi reprezintã
un progres.  De asemenea, observaþi cã algoritmul rãmîne corect
dacã eliminãm ultima linie din <TT>do</TT>, ºi în acest caz devine
ºi determinist!

<P>

<H2><A NAME="SECTION00022000000000000000">
Instanþe ºi probleme</A>
</H2>

<P>
O distincþie foarte importantã pe care trebuie s-o facem este între
<EM>clasa</EM> de probleme pe care o rezolvã un algoritm, ºi <EM>instanþele</EM> specifice ale acelei probleme.  De exemplu, algoritmul
descris mai sus rezolva <TT>toate</TT> problemele care conþin un vector
de <TT>n</TT> elemente ºi o valoare <TT>x</TT>, aducînd vectorul la forma
indicatã.  Cînd rulãm acest algoritm însã, o facem cu o
instanþã particularã a problemei: de exemplu vectorul cu <TT>n=5</TT>
elemente <TT>a = [1, 2, 5, 3, 2]</TT>, ºi cu <TT>x = 2</TT>.

<P>
Distincþia este esenþialã, mai ales cînd vrem sã evaluãm
eficacitatea unui algoritm.  Mãsurarea performanþei unui algoritm cu
ceasul în mînã nu este o operaþie foarte semnificativã, dacã
algoritmul va rezolva ºi alte instanþe ale problemei decît cea
mãsuratã.  Dacã algoritmul de mai sus, implementat pe un anumit
calculator, rezolvã instanþa indicatã în 5 milisecunde, asta nu
spune absolut nimic despre viteza lui pentru o cu totul altã
instanþã.  Dacã vrem sã evaluãm calitatea algoritmilor trebuie
sã gãsim o metodã care nu depinde de instanþe, ci de problema
însãºi.

<P>

<H2><A NAME="SECTION00023000000000000000">
Complexitate asimptoticã</A>
</H2>

<P>
O întrebare pe care ne-o putem imediat pune este: cît de bun este un
algoritm?  Nu se poate scrie un altul mai bun (care sã rezolve
aceeaºi problemã, fireºte)?  Pentru a putea rãspunde, trebuie sã
cãdem de acord asupra unei metode prin care mãsurãm calitãþile
unui algoritm; putem mãsura timpul lui de execuþie pentru o anumitã
problemã, sau cantitatea de memorie folositã, sau numãrul de
instrucþiuni care descriu programul, sau poate o altã dimensiune.

<P>
Dacã am doi algoritmi pentru aceeaºi problemã, atunci poate pentru
anumite <EM>instanþe</EM> ale problemei unul este mai rapid, iar pentru
alte instanþe celãlalt.  Dintre algoritmii de sortare sortarea prin
selecþie este preferatã pentru vectori mici, iar quicksort sau
heapsort pentru vectori mari.  Dacã valorile din vector sunt mici,
atunci le bate pe amîndouã radixsort.  ªi atunci, cum comparãm doi
algoritmi?

<P>
Existã un rãspuns relativ unanim acceptat la aceastã întrebare,
dar, înainte de a-l prezenta, trebuie încã odatã sã spunem cã
acesta este doar un punct de vedere în comparaþie, ºi cã în
practicã se pot prefera algoritmii ºi din alte motive.  Cel mai
interesant atribut al performanþei a fost judecat a fi <EM>timpul</EM>
de execuþie al unui algoritm.  Timpul este apoi asimilat cu <EM>numãrul de operaþii elementare</EM> pe care le efectueazã un algoritm
pentru a rezolva o problemã.

<P>
Din pãcate, chiar pentru o instanþã fixatã a unei probleme,
numãrarea instrucþiunilor executate este o sarcinã foarte
dificilã.  Din aceastã cauzã se socoteºte suficient a se mãsura
de cîte ori se repetã instrucþiunea care se executã <EM>cel mai
mult</EM>.  Aceasta este instrucþiunea dominantã, ºi se gãseºte de
regulã în interiorul tuturor buclelor.  Numãrul de repetiþii al
instrucþiunii dominante este o aproximaþie rezonabilã pentru
numãrul total de instrucþiuni executat de algoritm.  Oricum, din
moment ce nici o instrucþiune nu se mai executã atît de mult, dacã
înmulþim lungimea programului cu numãrul de repetiþii al
instrucþiunii dominante avem imediat o margine superioarã pentru
timpul de execuþie.  Vom vedea mai jos cã folosirea pentru a indica
complexitatea a ordinului de mãrime a unei funcþii face neimportant
un factor multiplicativ (anume lungimea programului).

<P>
Observaþi cã pentru instanþe diferite ale unei aceleiaºi probleme,
numãrul de instrucþiuni executat este în general diferit.  De
exemplu, acest scurt program, care cautã un numãr <TT>x</TT> în
vectorul <TT>a</TT>:

<P>
<PRE>
i = 1
do (i &lt;= n) and not (a[i] = x) -&gt; i := i + 1
od
</PRE>

<P>
va avea un timp de execuþie egal cu 1 dacã <TT>x = a[1]</TT>
sau cu <TT>n</TT> dacã <TT>x</TT> nici nu apare în vector.

<P>
Este de asemenea evident cã timpul de execuþie depinde adesea de
cantitatea datelor de intrare; în exemplele date mai sus el depinde
de numãrul de elemente din vectorul <TT>a</TT>.

<P>
Sã recapitulãm deci: avem un algoritm care rezolvã o clasã de
probleme.  Pentru fiecare instanþã, complexitatea algoritmului se
mãsoarã în numãrul de instrucþiuni executate pentru a rezolva
acea instanþã.

<P>
Noi ne dorim însã o mãsurã <EM>unicã, globalã</EM> a unui algoritm,
care sã-l caracterizeze, ºi nu complexitatea pentru fiecare
instanþã.  Atunci procedãm astfel: alegem o valoare <EM>arbitrarã</EM> care o numim <EM>mãrimea datelor de intrare</EM>.  Cînd
algoritmul lucreazã pe un vector (ca în exemplul de mai sus), o
alegere posibilã este numãrul de elemente.  În general valoarea
care caracterizeazã mãrimea datelor de intrare aratã cît de
multã informaþie este prezentã în datele de intrare.  Acesta este
un lucru normal, pentru cã ne putem aºtepta ca atunci cînd avem mai
multe date la intrare algoritmul sã lucreze mai multã vreme.

<P>
În acest fel partiþionãm mulþimea intrãrilor în mulþimi
(disjuncte) de ``mãrimi'' egale.  Pentru algoritmul precedent vom
avea astfel probleme de ``mãrime 1'': cele care au vectorul dintr-un
singur element.  Vom avea probleme de ``mãrime k'', cu vectori de
lungime k, º.a.m.d.  Fireºte, existã mai multe instanþe cu
mãrimea k.

<P>
Mai departe existã douã metode rãspîndite pentru a decide
complexitatea unui algoritm pentru date de mãrime fixatã.  Cea mai
comunã se cheamã: ``cel mai rãu caz'' (worst-case complexity).  Pe
scurt: fixãm mãrimea, mãsurãm numãrul de instrucþiuni pentru
fiecare instanþã de aceastã mãrime, ºi apoi luãm maximumul.

<P>
<BR><P></P>
<DIV ALIGN="CENTER">
T(n) = max<sub>marime(P) = n</sub> timp(P)
</DIV>
<BR CLEAR="ALL">
<P></P>

<P>
Complexitatea T pentru mãrimea fixatã n este maximumul timpilor
pentru toate problemele de mãrime n.

<P>
De exemplu, pentru algoritmul de cãutare expus mai sus, complexitatea
pentru vectori de mãrime n este n, pentru instanþele în care x nu se
regãseºte în vector.

<P>
În acest fel complexitatea unei probleme se exprimã ca <EM>o
funcþie de mãrimea problemei</EM>.

<P>
<PRE>
   date de intrare P
------------------------
| instante de marime 1 |     -&gt; max timp(P) = T(1)
------------------------ 
| instante de marime 2 |     -&gt; max timp(P) = T(2)    
------------------------
....
------------------------
| instante de marime n |     -&gt; max timp(P) = T(n)
------------------------
....
</PRE>

<P>
A doua metodã de a evalua complexitatea problemelor pentru o mãrime
fixatã este de a pune o distribuþie de probabilitate peste
instanþele de o anumitã mãrime (de exemplu toate pot fi egal
probabile) ºi de a evalua apoi valoarea medie a variabilei aleatoare
care descrie timpul de rulare.  Considerînd numai problemele de
mãrime n, dacã rezolvarea problemei x va dura un timp t(x) iar
problema se va ivi cu probabilitatea p(x), atunci complexitatea
algoritmului va fi <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
T(n) = \sum_{marime(x) = N} t(x) p(x).
\end{displaymath}
 -->

<IMG
 WIDTH="218" HEIGHT="55" BORDER="0"
 SRC="img7.png"
 ALT="\begin{displaymath}T(n) = \sum_{marime(x) = N} t(x) p(x).\end{displaymath}">
</DIV>
<BR CLEAR="ALL">
<P></P>
O astfel
de evaluare se numeºte ``cazul mediu'': ``average case complexity''.

<P>
Aceastã tehnicã este mult mai rar folositã, pentru cã:

<P>

<UL>
<LI>Este greu de argumentat o distribuþie de probabilitate pentru
un set de date de intrare (practic distribuþia afirmã ce ºansã are
fiecare instanþã de a fi întîlnitã cînd se ruleazã algoritmul).
De exemplu, pentru un algoritm pe grafuri, care este probabilitatea de
a primi un arbore?  Nu existã un rãspuns natural la aceastã
întrebare.
</LI>
<LI>În general este mult mai greu de evaluat analitic formula
obþinutã decît în cazul folosirii maximumului.
</LI>
</UL>

<P>
Metoda cu distribuþia de probabilitate a fost în general aplicatã
la algoritmi de cãutare ºi sortare, dar chiar ºi în aceste cazuri
simple rezultatele nu sunt întotdeauna facile.

<P>
De aici înainte vom presupune cã folosim complexitate ``worst
case''.  

<P>
Cînd cineva spune ``acesta este un algoritm de complexitate
n<sup>2</sup>, de fapt vrea sã spunã: ``pentru anumite de intrare de
mãrime n algoritmul executã instrucþiunea dominantã de cel mult
n<sup>2</sup> ori.''  Acest n este implicit deci dimensiunea datelor
de intrare.  Vom folosi ºi noi aceastã literã liber, fãrã a mai indica
sursa ei de provenienþã.

<P>

<H3><A NAME="SECTION00023100000000000000">
Simbolul lui Landau</A>
</H3>

<P>
Pentru cã de fapt noi socotim numai numãrul de repetiþii al
instrucþiunii dominante, ºi nu toate instrucþiunile executate, nu are
foarte mult sens sã comparãm între un algoritm cu complexitatea n ºi
unul cu complexitate n+1.  Toate instrucþiunile care nu au fost
mãsurate au o contribuþie care sã facã algoritmul cu n sã dureze în
realitate mai mult decît cel cu n+1.  Ceea ce trebuie sã comparãm de
fapt este <EM>ordinul de mãrime</EM> al complexitãþii, care pune în
evidenþã creºteri substanþial diferite.  Pentru a face evident acest
lucru se foloseºte o notaþie pentru ordinul de mãrime al unei funcþii,
introdus de fizicianul Lev Davidovich Landau.  Notaþia foloseºte
simbolul O (``o mare'') pentru a indica mulþimea funcþiilor care cresc
mai repede decît o funcþie datã.  Aceastã notaþie comparã numai
funcþii <EM>la limitã</EM>, în creºterea lor spre infinit.  <EM>Pentru
a putea compara complexitatea a doi algoritmi care rezolvã o aceeaºi
problemã în acest fel, trebuie ca ei sã poatã lucra cu probleme de
mãrimi arbitrar de mari!</EM>

<P>
<B>Definiþie:</B> fie datã o funcþie f : <B>N</B> --&gt; <B>N</B>,
astfel încît de la un rang încolo f(n) &gt; 0; atunci mulþimea
funcþiilor <EM>dominate</EM> de f se noteazã cu O(f) ºi se defineºte
astfel: <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
O(f) = \left\{ g : {\bf N} \rightarrow {\bf N}
\,|\, \exists N_0, \exists c < \infty \; \forall n > N_0, \,
\frac{g(n)}{f(n)} < c \right\}.
\end{displaymath}
 -->
<IMG
 WIDTH="430" HEIGHT="51" BORDER="0"
 SRC="img13.png"
 ALT="O(f) definit">
</DIV>
<BR CLEAR="ALL">
<P></P> În cuvinte, o funcþie este în
mulþimea O(f) dacã la ``creºte mai încet'' decît f la
infinit.  De exemplu, funcþia g(n) = n este în mulþimea O(n<sup>2</sup>),
pentru cã <!-- MATH
 $g(n)/n^2 \rightarrow 0$
 -->
<IMG
 WIDTH="101" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img16.png"
 ALT="$g(n)/n^2 \rightarrow 0$">.  În general, un polinom de grad
mai mic decit k este în mulþimea O(n^k).

<P>
Din pãcate notaþia se foloseºte în uzajul comun în mod greºit,
scriindu-se f = O(g) în loc de <IMG
 WIDTH="74" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$f \in O(g)$">: O(g) este o <EM>mulþime de funcþii</EM>, toate
 dominate de g. 

<P>
Din considerentele indicate, metoda preferatã pentru a indica
complexitatea unui algoritm este de a o face prin ordinul de mãrime
al funcþiei sale de complexitate.  Din cauza cã analizeazã aceastã
comportare spre infinit complexitatea algoritmilor se numeºte
``complexitate asimptoticã''.

<P>
Ce înseamnã deci cã un algoritm ``are o complexitate O(n log
n)''?  Înseamnã cã pe mãsurã ce datele de intrare cresc în
mãrime ca n, numãrul de operaþii fãcut de algoritm în raport cu
mãrimea datelor de intrare este <EM>mai micã</EM> de n log n ori.

<P>
Astfel complexitatea asimptoticã exprimã concis o limitã
superioarã a timpului de execuþie a unui algoritm.  O grãmadã de
informaþie se pierde din descrierea complexitãþii unui algoritm
dînd numai ordinul de mãrime:

<P>

<UL>
<LI>În primul rînd funcþia al cãrei ordin de mãrime este
evaluatã era obþinutã luînd maximumul peste toate instanþele de o
anumitã mãrime.

<P>
</LI>
<LI>În al doilea rînd, dacã <IMG
 WIDTH="74" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$f \in O(g)$"> asta înseamnã numai
cã <EM>de la un rang încolo</EM> f e ``mai micã'' decît g; rangul
acesta ar putea foarte bine fi mai mare decît numãrul de atomi din
univers, deci mai mare decît al oricãrei probleme practice pe care
vrem s-o rezolvãm.

<P>
</LI>
<LI>Notaþia cu O indicã numai <EM>limita superioarã</EM> a unei
funcþii; observaþi cã atît <!-- MATH
 $f(n) = n \in O(n^2)$
 -->
<IMG
 WIDTH="141" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img26.png"
 ALT="$f(n) = n \in O(n^2)$"> cît ºi <!-- MATH
 $g(n) =
n^2 \in O(n^2)$
 -->
<IMG
 WIDTH="147" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img27.png"
 ALT="$g(n) =
n^2 \in O(n^2)$">.  Numai informaþia cã f ºi g sunt în aceeaºi
clasã nu ne permite de fapt sã le comparãm între ele.  Pentru a
indica ºi faptul cã limita se atinge, se foloseºte o altã
notaþie, cu <IMG
 WIDTH="18" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img28.png"
 ALT="$\Omega$"><A NAME="tex2html1"
  HREF="#foot170"><SUP>1</SUP></A>.  De exemplu, dacã
ºtiu despre un algoritm doar cã este O(n<sup>2</sup>, asta spune ceva.  Dar
dacã mi se spune ºi cã existã o serie de instanþe, crescãtoare
în mãrime, pe care algoritmul face c n<sup>2</sup> + ..., atunci
ºtiu mult mai mult; ºtiu de exemplu cã algoritmul este ``mai
prost'' decît un algoritm O(n), iar complexitatea lui poate fi
indicatã cu semnul <IMG
 WIDTH="50" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img32.png"
 ALT="$\Omega(n^2)$">.
</LI>
</UL>

<P>
Cu toate aceste dezavantaje, notaþia cu O s-a impus, ºi s-a
dovedit în general destul de eficace pentru a caracteriza algoritmii.
Proprietãþile notaþiei O sunt foarte interesante, dar depãºesc
cadrul acestui articol; în general sunt destul de intuitive (de
exemplu: dacã f = O(g) ºi g = O(h), atunci f = O(h)$, etc.

<P>
În final, reluînd o observaþie de la începutul secþiunii, sã
observãm cã într-adevãr n = O(n+1) ºi n+1 = O(n), aºa cã
într-adevãr notaþia cu O aruncã termenii nesemnificativi, ºi
faptul cã am numãrat numai instrucþiuni dominante nu are nici o
importanþã.  Mai exact, este foarte uºor de arãtat cã timpul real
de execuþie a unui algoritm este O(numãrul de repetiþii al
instrucþiunii dominante).

<P>

<H2><A NAME="SECTION00024000000000000000">
Complexitatea revizuitã</A>
</H2>

<P>
Am admis tacit cã toate operaþiile elementare se pot efectua în
timp unitar, dar acest lucru poate adesea sã ne inducã în eroare.
De exemplu, atunci urmãtorul algoritm, care calculeazã numãrul
2<sup>2<sup>...<sup>2</sup></sup></sup>, funcþioneazã în n
paºi:

<P>
<PRE>
x, i := 2, 1
do i &lt;= n -&gt; x, i := x * x, i+1
od
</PRE>

<P>
Numãrul care se obþine în acest fel este extrem de lung, ºi este
mult mai rezonabil sã presupunem cã operaþiile cu numere iau un
timp care depinde de lungimea numãrului în biþi.

<P>
Vom ignora însã aceste considerente uºor ezoterice, ºi ne vom
mulþumi sã presupunem cã în algoritmii noºtri toate operaþiile
pot fi fãcute în timp constant.

<P>

<H2><A NAME="SECTION00025000000000000000">
Complexitatea unei probleme</A>
</H2>

<P>
Un algoritm rezolvã o problemã.  Adesea pentru a rezolva o aceeaºi
problemã putem folosi mai mulþi algoritmi, poate cu complexitãþi
diferite.  Existã cel puþin 30 de metode de a sorta un ºir de
valori, de exemplu!  Putem vorbi deci de complexitatea unui algoritm,
dar ºi de <EM>complexitatea unei probleme</EM>.  Complexitatea unei
probleme este complexitatea celui mai ``rapid'' algoritm care o poate
rezolva.  Complexitatea unei probleme este deci o limitã inferioarã
a eficacitãþii cu care putem rezolva o problemã: orice algoritm
care va rezolva acea problemã va fi mai complex decît complexitatea
problemei.

<P>
În general este extrem de dificil de evaluat complexitatea unei
probleme, pentru cã rareori putem demonstra cã un algoritm este cel
mai bun posibil.  Tabloul aratã cam aºa:

<P>
<PRE>
limita inferioara          complexitatea          cel mai bun 
      dovedita             problemei              algoritm cunoscut
---------|------------------?----------------------|----------------
         f                                         g
</PRE>

<P>
Cu alte cuvinte, putem spune: ``problema asta nu se poate face mai
repede de f, ºi noi ºtim s-o rezolvãm în g''.  Dar care este
complexitatea realã, ºi care este algoritmul care rezolvã problema
<EM>optim</EM>, asta foarte rar se poate spune.

<P>
Pentru o problemã atît de banalã ca înmulþirea a douã numere,
considerînd numerele scrise în baza 2, iar mãrimea lor numãrul
total de biþi n, complexitatea celui mai bun algoritm de
înmulþire cunoscut este de O(n log n log log n), dar limita
inferioarã doveditã este de n.  Sau pentru înmulþirea a douã
matrici de n*n elemente: se gãsesc încontinuu algoritmi
din ce în ce mai buni (asimptotic vorbind), dar limita inferioarã de
n<sup>2</sup> este încã departe de cel mai bun (ºi foarte sofisticat
algoritm), care este aproximativ O(n<sup>2,3</sup>) (comparaþi cu
algoritmul ``naiv'' imediat, care este O(n<sup>3</sup>)).

<P>

<H2><A NAME="SECTION00026000000000000000">
Clasa P; alte clase deterministe</A>
</H2>

<P>
Unele probleme se pot rezolva, altele nu.  De exemplu, o problemã
notorie, a cãrei imposibilitate este riguros demonstratã în anii
'30 de cãtre matematicianul englez Alan Turing, este de a decide
dacã un program se va opri vreodatã pentru o anumitã instanþã a
datelor de intrare.

<P>
Pe de altã parte, chiar între problemele care pot fi rezolvate,
teoreticienii trag o linie imaginarã între problemele care au
rezolvãri ``rezonabil'' de rapide, ºi restul problemelor, care se
numesc ``intratabile''.

<P>
În mod arbitrar, dar nu ne-justificabil, o problemã se numeºte
``intratabilã'' dacã complexitatea ei este exponenþialã în
mãrimea datelor de intrare.  (Nu uitaþi, este vorba de complexitate
``worst-case'' asimptoticã.)  O problemã este ``tratabilã'' dacã
putem scrie complexitatea ei sub forma unui polinom, de un grad
oricît de mare.  

<P>
Mulþimea tuturor problemelor de decizie (adicã a problemelor la care
rãspunsul este <EM>da</EM> sau <EM>nu</EM>) cu complexitate polinomialã
se noteazã cu P (de la polinom).  De exemplu, problema de a gãsi
dacã o valoare se aflã într-un vector este în clasa P; algoritmul
exhibat mai sus este un algoritm în timp linear (O(n)) pentru a
rãspunde la aceastã întrebare.

<P>
Un exemplu de problemã cu complexitate exponenþialã
(ne-polinomialã)?  Iatã unul: dacã se dã o formulã logicã peste
numerele reale, cu cuantificatori existenþiali (<IMG
 WIDTH="16" HEIGHT="20" ALIGN="BOTTOM" BORDER="0"
 SRC="img45.png"
 ALT="$\exists$">) ºi
universali (<IMG
 WIDTH="16" HEIGHT="20" ALIGN="BOTTOM" BORDER="0"
 SRC="img46.png"
 ALT="$\forall$">), care foloseºte numai operaþii de adunare,
comparaþii cu &lt; ºi conectori logici (<!-- MATH
 $\land, \lor, \Rightarrow,
\ldots$
 -->
<IMG
 WIDTH="90" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img48.png"
 ALT="$\land, \lor, \Rightarrow,
\ldots$">), este formula adevãratã?  (Un exemplu de formulã:
``<!-- MATH
 $\forall x \exists y \forall z \; (x + z < y) \land (2x - z >
y)$
 -->
<IMG
 WIDTH="268" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img49.png"
 ALT="$\forall x \exists y \forall z \; (x + z &lt; y) \land (2x - z &gt;
y)$">'').  Decizia se poate face numai într-un timp exponenþial în
lungimea formulei (pentru anumite instanþe), dar demonstraþia nu
este de loc simplã.

<P>
(Ca o curiozitate: existã ºi probleme cu o complexitate
``ne-elementarã'', care este mai mare decît complexitatea oricãrei
probleme exponenþiale.  O astfel de problemã este cea de decizie a
adevãrului unei formule în teoria numitã S1S, sau ``teoria
monadicã a succesorilor de ordinul 2''.  Nu vã lãsaþi intimidaþi
de terminologie: aceasta este practic o teorie logicã peste numerele
naturale, în care avem voie sã scriem formule cu cuantificatori ºi
conectori logici, ca mai sus, dar avem ºi dreptul sã cuantificãm
peste mulþimi.  Complexitatea deciziei unei formule logice într-o
astfel de teorie este mai mare decît
<!-- MATH
 $\underbrace{2^{2^{\ldots^n}}}_k$
 -->
<IMG
 WIDTH="42" HEIGHT="60" ALIGN="MIDDLE" BORDER="0"
 SRC="img50.png"
 ALT="$\underbrace{2^{2^{\ldots^n}}}_k$"> pentru orice k natural!)

<P>

<H2><A NAME="SECTION00027000000000000000">
Clasa NP; algoritmi nedeterminiºti; NP-completitudine</A>
</H2>

<P>
Algoritmii cu care suntem obiºnuiþi sã lucrãm zi de zi sunt <EM>determiniºti</EM>.  Asta înseamnã cã la un moment dat evoluþia
algoritmului este unic determinatã, ºi ca instrucþiunea care
urmeazã sã se execute este unic precizatã în fiecare moment.  Am
vãzut însã cã limbajul pe care l-am folosit ne permite scrierea
unor algoritmi care au mai multe posibilitãþi la un moment dat;
construcþia <TT>if</TT> din limbajul cu gãrzi permite evaluarea
oricãrei instrucþiuni care are garda adevãratã.

<P>
Acest tip de algoritmi este surprinzãtor de bogat în consecinþe cu
valoare teoreticã.  Aceºti algoritmi nu sunt direct aplicabili,
însã studiul lor dã naºtere unor concepte foarte importante.

<P>
Surprinzãtoare este ºi definiþia corectitudinii unui astfel de
algoritm.  Un algoritm nedeterminist este corect dacã <EM>existã</EM> o
posibilitate de executare a sa care gãseºte rãspunsul corect.  Pe
mãsurã ce un algoritm nedeterminist se executã, la anumiþi paºi
se confruntã cu alegeri nedeterministe.  Ei bine, dacã la fiecare
pas existã o alegere, care fãcutã sã ducã la gãsirea soluþiei,
atunci algoritmul este numit corect.

<P>
Astfel, un algoritm nedeterminist care cautã ieºirea dintr-un
labirint ar arãta cam aºa:

<P>
<PRE>
do not iesire(pozitie_curenta) -&gt;
    if not perete(nord(pozitie_curenta)) -&gt; 
            pozitie_curenta := nord(pozitie_curenta)
    [] not perete(est(pozitie_curenta)) -&gt; 
            pozitie_curenta := est(pozitie_curenta)
    [] not perete(sud(pozitie_curenta)) -&gt; 
            pozitie_curenta := sud(pozitie_curenta)
    [] not perete(vest(pozitie_curenta)) -&gt; 
            pozitie_curenta := vest(pozitie_curenta)
    fi
od
</PRE>

<P>
Pe scurt algoritmul se comportã aºa: dacã la nord nu e perete mergi
încolo, sau, poate, dacã la sud e liber, mergi încolo, sau la est,
sau la vest.  În care dintre direcþii, nu se precizeazã (este
ne-determinat).  Este clar cã dacã existã o ieºire la care se
poate ajunge, existã ºi o suitã de aplicãri ale acestor reguli
care duce la ieºire.

<P>
Utilitatea practicã a unui astfel de algoritm nu este imediat
aparentã: în definitiv pare sã nu spunã nimic util: soluþia este
fie spre sud, fie spre nord, fie spre este, fie spre vest.  Ei ºi?
Este clar cã aceºti algoritmi nu sunt direct implementabili pe un
calculator real.

<P>
În realitate existenþa un astfel de algoritm deja înseamnã destul
de mult.  Înseamnã în primul rînd cã problema se poate rezolva
algoritmic; vã reamintesc cã existã probleme care nu se pot rezolva
deloc.

<P>
În al doilea rînd, se poate arãta cã fiecare algoritm
nedeterminist se poate transforma într-unul determinist într-un mod
automat.  Deci de îndatã ce ºtim sã rezolvãm o problemã într-un
mod nedeterminist, putem sã o rezolvãm ºi determinist!
Transformarea este relativ simplã: încercãm sã mergem pe <EM>toate</EM> drumurile posibile în paralel, pe fiecare cîte un pas.  (O
astfel de tehnicã aplicatã în cazul labirintului se transformã în
ceea ce se cheamã ``flood fill'': evoluez radial de la poziþia de
plecare în toate direcþiile).

<P>
Clasa tuturor problemelor care se pot rezolva cu algoritmi
nedeterminiºti într-un timp polinomial se noteazã cu NP
(Nedeterminist Polinomial).  Este clar cã orice problemã care se
aflã în P se aflã ºi în NP, pentru cã algoritmii determiniºti
sunt doar un caz extrem al celor determiniºti: în fiecare moment au
o singurã alegere posibilã.

<P>
Din pãcate transformarea într-un algoritm determinist se face
pierzînd din eficienþã.  În general un algoritm care opereazã în
timp nedeterminist polinomial (NP) poate fi transformat cu uºurinþã
într-un algoritm care merge în timp exponenþial (EXP).  Avem deci o
incluziune de mulþimi între problemele de decizie: P <IMG
 WIDTH="19" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$\subseteq$"> NP
<IMG
 WIDTH="19" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$\subseteq$"> EXP.

<P>
Partea cea mai interesantã este urmãtoarea: ºtim cu certitudine cã
P <IMG
 WIDTH="19" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.png"
 ALT="$\not=$"> EXP.  Însã nu avem <EM>nici o idee</EM> despre relaþia de
egalitate între NP ºi P sau între NP ºi EXP.  <EM>Nu existã nici
o demonstraþie care sã infirme cã problemele din NP au algoritmi
eficienþi, determinist polinomiali!</EM>  Problema P=NP este cea mai
importantã problemã din teoria calculatoarelor, pentru cã de
soluþionarea ei se leagã o grãmadã de consecinþe importante.

<P>
Problema aceasta este extrem de importantã pentru întreaga
matematicã, pentru cã însãºi demonstrarea teoremelor este un
proces care încearcã sã verifice algoritmic o formulã logicã (cum
am vãzut mai sus de pildã); teoremele la care existã demonstraþii
``scurte'' pot fi asimilate cu problemele din mulþimea NP (la fiecare
pas dintr-o demonstraþie putem aplica mai multe metode de
inferenþã, în mod nedeterminist; un algoritm trebuie sã ghiceascã
înºiruirea de metode aplicate pentru demonstrarea enunþului); dacã
orice problemã din NP este ºi în P, atunci putem automatiza o mare
parte din demonstrarea de teoreme în mod eficient!

<P>
Problema P=NP este foarte importantã pentru criptografie: decriptarea
este o problemã din NP (cel care ºtie cheia ºtie un algoritm
determinist polinomial de decriptare, dar cel care nu o ºtie are în
faþa o problemã pe care nedeterminist o poate rezolva în timp
polinomial).  Dacã s-ar demonstra cã P=NP acest lucru ar avea
consecinþe extrem de importante, iar CIA si KGB ar fi într-o
situaþie destul de proastã, pentru cã toate schemele lor de
criptare ar putea fi sparte în timp polinomial (asta nu înseamnã
neapãrat foarte repede, dar oricum, mult mai repede decît timp
exponenþial)!

<P>
Mai mult, în 1971 Cook a demonstrat cã existã o problemã specialã
în NP (adicã pentru care se poate da un algoritm eficient
nedeterminist), numitã <EM>problema satisfiabilitãþii</EM> (notatã cu
SAT).  Problema este foarte simplã: dacã se dã o formulã booleanã
care cuprinde mai multe variabile, poate fi formula fãcutã
adevãratã dînd anumite valori variabilelor?  De pildã formula
<!-- MATH
 $(x_1 \land x_2) \lor (x_1 \land \lnot x_2)$
 -->
<IMG
 WIDTH="173" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img54.png"
 ALT="$(x_1 \land x_2) \lor (x_1 \land \lnot x_2)$"> devine adevãratã
 pentru x<sub>1</sub>=adevãrat ºi x<sub>2</sub> arbitrar.  SAT este
 foarte importantã, pentru cã Cook a demonstrat cã dacã SAT poate fi
 rezolvatã în P (adicã folosind un algoritm determinist polinomial),
 atunci <EM>orice</EM> problemã din NP poate fi rezolvatã în timp
 polinomial! Problema satisfiabilitãþii este cumva ``cea mai grea
 problemã'' din NP, pentru cã rezolvarea oricãrei alte probleme din NP
 se poate face ``mai repede'' decît a ei.  Din cauza asta SAT se
 numeºte o problemã <EM>NP-completã</EM>.

<P>
De la Cook încoace s-au mai descoperit cîteva sute de probleme
NP-complete.  Unele probleme care se ivesc foarte adesea în practicã
s-au dovedit NP-complete!  Acesta este un alt motiv pentru care clasa
atît de abstractã NP a problemelor cu algoritmi nedeterminiºti este
atît de importantã: foarte multe probleme practice au algoritmi
polinomiali nedeterminiºti, dar cei mai buni algoritmi determiniºti
iau un timp exponenþial!

<P>
Iatã cîteva exemple de probleme NP-complete:

<P>

<UL>
<LI>Problema comis-voiajorului (turneu Hamiltonian de cost minim):
dîndu-se o reþea de oraºe, o reþea de drumuri între oraºe ºi o
lungime k, existã un traseu de cost mai mic decît k trecînd
prin fiecare oraº o singurã datã ºi revenind la punctul de
plecare?

<P>
</LI>
<LI>Dîndu-se o mulþime de numere naturale, se poate împãrþi în
douã mulþimi de numere de sume egale<A NAME="tex2html2"
HREF="#foot261"><SUP>2</SUP></A>?

<P>
</LI>
<LI>``Clica'': dîndu-se un graf G ºi un numãr k, are G un
subgraf complet cu k vîrfuri (adicã o mulþime de k vîrfuri
unite fiecare cu fiecare)?

<P>
</LI>
<LI>``Acoperire'': dîndu-se un graf G ºi un numãr k, pot
alege k vîrfuri în aºa fel încît toate muchiile din G au un
capãt ales?
</LI>
</UL>

<P>
O cantitate enormã de efort ºi ingeniozitate a fost risipitã pentru
a încerca sã se demonstreze cã P=NP sau opusul acestei afirmaþii,
dar nici un rezultat concret nu a fost obþinut.  Credinþa
cvasi-unanimã este cã P<IMG
 WIDTH="19" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.png"
 ALT="$\not=$">NP, dar numai matematica poate oferi
vreo certitudine...

<P>
Din cauzã cã foarte multe probleme practice sunt în NP, ºi ca
aparent nu putem avea algoritmi determiniºti eficace pentru ele,
cercetãtorii ºi-au îndreptat atenþia asupra unor clase noi de
algoritmi, care vor face obiectul secþiunilor urmãtoare.

<P>

<H1><A NAME="SECTION00030000000000000000">
Algoritmi aproximativi</A>
</H1>

<P>
În secþiunile care urmeazã folosim tot timpul premiza <EM>nedemonstratã</EM> cã P<IMG
 WIDTH="19" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.png"
 ALT="$\not=$">NP.  Dacã P=NP, atunci problemele pe care
ne batem capul sã le rezolvãm prin metode ciudate pot fi de fapt
rezolvate exact ºi eficient, aºa cã restul articolului cade ºi nu
se mai ridicã.

<P>

<H2><A NAME="SECTION00031000000000000000">
Optim ºi aproximare</A>
</H2>

<P>
Foarte multe probleme de optimizare se dovedesc a fi
NP-complete<A NAME="tex2html3"
  HREF="#foot204"><SUP>3</SUP></A>: probleme în care vrem sã
calculãm maximumul sau minimumul a ceva.  Bine, dar dacã de fapt mã
mulþumesc sã obþin o valoare care nu este chiar optimã, dar este
``suficient de aproape''?  Poate în acest caz complexitatea problemei
poate fi redusã, ºi sunt în stare sã scriu un algoritm
eficient... (polinomial).  Avem deci de a face cu un compromis:

<P>
<PRE>
solutie optima;                         solutie sub-optima:
                      &lt;--------------&gt;
algoritm NP sau                         algoritm polinomial
algoritm exponential
</PRE>

<P>
Într-adevãr, aceastã metodã se bucurã de un oarecare succes, dar
nu de unul general.  Algoritmii care rezolvã o problemã de
optimizare în speranþa unui rezultat sub-optimal se numesc
``algoritmi aproximativi''.

<P>
Existã o sumedenie de rezultate în ceea ce priveºte problemele de
optimizare ºi aproximãrile lor.  Se demonstreazã cã unele probleme
pot fi foarte bine aproximate (putem obþine soluþii cît dorim de
aproape de optim în timp polinomial), altele pot fi aproximate numai
în anumite limite (de exemplu putem obþine soluþii de 2 ori mai
slabe, dar deloc mai bune), sau altele nu pot fi aproximate deloc (în
ipoteza cã P<IMG
 WIDTH="19" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.png"
 ALT="$\not=$">NP).

<P>
Teoria algoritmilor aproximativi este relativ recentã (deºi ideea
existã de multã vreme), iar unele rezultate sunt extrem de
complicate.  Ne vom mulþumi sã dãm niºte exemple pentru a ilustra
algoritmi aproximativi în acþiune, ºi tipul de rezultate care se
pot obþine.

<P>
Vom ilustra douã rezultate diferite din teoria algoritmilor
aproximativi: algoritmi de aproximare <EM>relativã</EM>, algoritmi de
aproximare <EM>absolutã</EM> a soluþiei (lãmurim terminologia
imediat).

<P>
Sã notãm o instanþã a unei probleme cu I.  Fie OPT(I) valoarea
soluþiei optime pentru acea instanþã (care <EM>existã</EM>, dar pe
care nu ºtim s-o calculãm eficient), ºi fie A(I) valoarea
calculatã de algoritmul nostru aproximativ.  Numim aproximaþia
<EM>absolutã</EM> dacã existã un numãr K, independent de instanþa I,
care are proprietatea cã |OPT(I) - A(I)| &lt; K.  Numim aproximaþia
<EM>relativã</EM> dacã existã un R (numit ``performanþã'') astfel
ca pentru orice instanþã I avem (A(I) / OPT(I)) &lt; R (dacã
problema cautã un maximum, atunci fracþia din definiþie trebuie
inversatã).

<P>

<H2><A NAME="SECTION00032000000000000000">
Problema rucsacului</A>
</H2>

<P>
Iatã o variantã a problemei rucsacului care este NP-completã (nu am
discutat deloc în acest articol despre cum se demonstreazã aºa
ceva, aºa cã trebuie sã mã credeþi pe cuvînt), dar pentru care
se poate obþine cu foarte mare uºurinþã un algoritm aproximativ
relativ eficient.

<P>
Se dau o mulþime (mare) de rucsaci de capacitate egalã (cunoscutã,
un numãr natural).  Se mai dã o mulþime finitã de obiecte, fiecare
de un volum cunoscut (numãr natural).  Întrebarea este: care este
numãrul minim de rucsaci necesari pentru a împacheta toate
obiectele?

<P>
Problema rucsacului are un algoritm de aproximare relativã cu
performanþã 2.

<P>
Algoritmul este banal: metoda ``greedy'': pune de la stînga fiecare
greutate în primul rucsac liber:

<P>
<PRE>
Date de intrare: nrobiecte, capacitate, marime[1..nrobiecte]

Initializari:
o, folositi := 1, 0
do o &lt;= nrobiecte -&gt; liber[o] := capacitate od

Algoritm:
o := 1
do o &lt;= nrobiecte -&gt; 
    r := 1
    do (liber[r] &lt; marime[o]) -&gt; r := r+1
    od
    folositi, liber[r], o := 
        max(r, folositi), liber[r] - marime[o], o+1
od
</PRE>

<P>
Cum demonstrãm cã performanþa relativã este 2?  Foarte simplu: sã
observãm cã la sfîrºitul algoritmului nu pot exista doi rucsaci
folosiþi pe mai puþin de jumãtate amîndoi, pentru cã atunci
conþinutul celui de-al doilea ar fi fost vãrsat în primul.  Cu alte
cuvinte, la terminare avem: liber[r] &lt; 1/2 capacitate.  Dar dacã
însumãm pentru toþi rucsacii, vom avea cã spaþiul liber este mai
puþin de jumãtate din cel disponibil, deci cel ocupat este mai mult
de jumãtate.  Dar dacã obiectele au mãrime totalã M, atunci
orice-am face nu putem folosi mai puþin de M spaþiu total pentru a
le împacheta.  Dar noi am folosit mai puþin de M + M = 2M, deci
algoritmul are performanþã 2.  QED.

<P>

<H2><A NAME="SECTION00033000000000000000">
Performanþa absolutã; un rezultat negativ</A>
</H2>

<P>
Vom folosi o altã problemã NP-completã, pentru care avem imediat un
algoritm de aproximare relativã de performanþã 2, dar pentru care
vom demonstra cã nu existã nici un algoritm de aproximare absolutã.

<P>
Problema este cea a acoperirii unui graf, enunþatã mai sus.  Ca
problemã de optimizare, ea se enunþã astfel: ``care este numãrul
minim de vîrfuri care trebuie ``acoperite'' astfel ca toate muchiile
dintr-un graf sã fie atinse?''

<P>
Pentru aceastã problemã algoritmul greedy nu face multe parale ca
algoritm de aproximare.  Existã însã un algoritm relativ simplu, cu
performanþã 2, care se foloseºte însã de un alt algoritm clasic,
cel al ``cuplãrii'' (matching).  Fãrã a intra în detalii, existã
un algoritm polinomial relativ sofisticat pentru a calcula cuplãri
maximale pe grafuri<A NAME="tex2html4"
  HREF="#foot216"><SUP>4</SUP></A>.  Calculãm o cuplare maximalã, dupã care luãm
capetele tuturor muchiilor care o formeazã: astfel obþinem o
acoperire (uºor de demonstrat) care e cel mult dublã ca mãrime
faþã de optim (pentru cã în optim trebuie sã se gãseascã cel
puþin cîte un vîrf pentru fiecare muchie din cuplare, iar noi am
luat cîte douã).

<P>
Iatã ºi un rezultat negativ interesant: pentru orice K fixat, nu
existã nici un algoritm care sã dea pentru problema acoperirii o
soluþie aproximativã absolutã la distanþa K de cea optimã
pentru orice instanþã.  Demonstraþia este foarte simplã, odatã ce
ai vãzut ideea, ºi se bazeazã pe ``tehnica amplificãrii''.  Iatã
cum se face, prin reducere la absurd:

<P>
Sã presupunem cã avem un algoritm A care calculeazã pentru orice
graf o acoperire care este cu cel mult K noduri mai mare ca cea
optimã (K e fixat).  Cu alte cuvinte |OPT(G) - A(G)| &lt; K.  Sã
luãm o instanþã arbitrarã a problemei cuplãrii, G.  Formãm un
nou graf G<sub>1</sub> din G, care nu este conex, ºi care constã din
K+1 copii ale lui G, alãturate.  Aceasta este o instanþã perfect
corectã a problemei acoperirii, aºa cã rulãm pe ea algoritmul
nostru A.  Acesta va oferi o acoperire care are cel mult cu K noduri
mai mult decît acoperirea optimã.  (Vã reamintesc notaþiile:
OPT(G) este valoarea optimã: numãrul minim de noduri pentru a
acoperi muchiile, iar A(G) este valoarea calculatã de algoritmul
nostru.

<P>
Datoritã faptului cã cele K+1 copii ale lui G sunt neconectate,
optimumul pentru G<sub>1</sub> este reuniunea a K+1 optimumuri pentru
G.  Din cauza asta avem relaþia OPT(G<sub>1</sub>) = (K+1) OPT(G).
Fie acum H copia lui G pe care A a marcat cele mai multe vîrfuri;
atunci A(G<sub>1</sub>) &lt;= (K+1) A(H).  Dar din proprietãþile lui A
avem: |OPT(G<sub>1</sub>) - A(G<sub>1</sub>)| &lt; K, sau |(K+1)
OPT(H) - (K+1) A(H)| < K, ori |OPT(H) - A(H)| < K/(K+1) &lt; 1.  Însã
ºtim cã OPT(H) ºi A(H) sunt numere naturale, deci am obþinut OPT(H) =
A(H)!

<P>
Asta înseamnã cã dacã avem un algoritm aproximativ absolut pentru
problema acoperirii, putem imediat construi un algoritm exact la fel
de rapid.  Ori asta ar însemna cã P=NP, ceea ce am presupus fals.

<P>
Exemplele pe care le-am ales sunt în mod deliberat simple; teoria
algoritmilor aproximativi este în plinã dezvoltare ºi are rezultate
foarte spectaculoase ºi în general complicate.  În orice caz,
aplicabilitatea ei este imediatã, pentru cã multe probleme practice
care nu pot aºtepta au numai rezolvãri aproximative.

<P>

<H1><A NAME="SECTION00040000000000000000">
Algoritmi Monte Carlo</A>
</H1>

<P>
O tehnicã foarte spectaculoasã pentru rezolvarea problemelor este
cea a folosiri numerelor aleatoare.  Practic algoritmii aleatori sunt
identici cu cei obiºnuiþi, dar folosesc în plus o nouã
instrucþiune, care s-ar putea chema ``dã cu banul''.  Aceastã
instrucþiune genereazã un bit arbitrar ca valoare.

<P>
În mod paradoxal, incertitudinea ne poate oferi mai multã putere...

<P>
La ce se foloseºte aleatorismul?  Sã ne amintim cã în general
complexitatea unei probleme este definitã luînd în considerare cea
mai defavorabilã instanþã.  De exemplu, pentru problema comis
voiajorului, faptul cã aceastã problemã este NP-completã nu
înseamnã cã nu putem rezolva nici o instanþã a ei, ci cã existã
instanþe pentru care algoritmii cunoscuþi nu au prea multe ºanse
sã termine în curînd.

<P>
Acest lucru este adevãrat ºi pentru alte clase de algoritmi; de pildã
algoritmul quicksort are pentru majoritatea vectorilor de intrare o
comportare O(n log n).  Dacã însã datele de intrare sunt prost
distribuite, atunci quicksort poate face n<sup>2</sup> comparaþii.
Pentru n=100 asta înseamnã de 10 ori mai mult!  Numãrul de instanþe
pentru care quicksort este slab este mult mai mic decît numãrul de
instanþe pentru care merge bine.  Ce te faci însã dacã într-un anumit
context lui quicksort i se dau numai date rele?  (Datele preluate din
mãsurãtori reale sunt foarte rar complet uniform distribuite).  O
soluþie paradoxalã constã în a <EM>amesteca</EM> aleator vectorul
înainte de a-l sorta.

<P>
Complexitatea <EM>medie</EM> (average case) a lui quicksort este O(n
log n).  Complexitatea în cazul cel mai rãu (worst case) este
O(n<sup>2</sup>).  Dacã datele vin distribuite cu probabilitate mare
în zona ``rea'', atunci amestecîndu-le putem transforma instanþe care
picã în zona ``worst-case'' în instanþe de tip ``average-case''.
Fireºte, asta nu înseamnã ca nu putem avea ghinion, ºi ca amestecarea
sã producã tot o instanþã ``rea'', dar <EM>probabilitatea</EM> ca
acest lucru sã se întîmple este foarte micã, pentru cã quicksort are
puþine instanþe rele<A NAME="tex2html5"
HREF="#foot221"><SUP>5</SUP></A>.

<P>
Acesta este un caz de folosire a aleatorului pentru a îmbunãtãþi
performanþa medie a unui algoritm.

<P>
Cîteodatã cîºtigul este ºi mai mare, pentru cã putem rezolva
probleme NP-complete foarte rapid folosind aleatorismul.  De obicei
avem însã un preþ de plãtit.  Cînd folosim algoritmi din clasa
prezentatã mai jos, putem risca sã nu primim rãspunsul corect.

<P>

<H1><A NAME="SECTION00050000000000000000">
Algoritmi Las Vegas</A>
</H1>

<P>
Evoluþia unui algoritm care foloseºte numere aleatoare nu mai
depinde numai de datele de intrare, ci ºi de numerele aleatoare pe
care le genereazã.  Dacã are ``noroc'' algoritmul poate termina
repede ºi bine; dacã dã prost cu zarul, ar putea eventual chiar
trage o concluzie greºitã.  (În cazul quicksort de mai sus
rãspunsul este întotdeauna corect, dar cîteodatã vine mai greu.
Aceasta este diferenþa dintre algoritmii Monte Carlo, mereu corecþi,
ºi cei Las Vegas, care pot uneori, rar, greºi.)

<P>
Vom defini acum algoritmii probabiliºti pentru probleme de decizie
(þineþi minte, la care rãspunsul este Da sau Nu).  Majoritatea
problemelor pot fi exprimate în forma unor probleme de decizie, deci
simplificarea nu este prea drasticã.

<P>
Existã douã clase de algoritmi probabiliºti, dar ne vom concentra
atenþia numai asupra uneia dintre ele, pentru care vom da ºi douã
exemple simple ºi spectaculoase.  Vom defini totodatã clasa
problemelor care pot fi rezolvate probabilist în timp polinomial,
numitã RP (Random Polinomial).

<P>
Observaþi cã dacã indicãm de la început care sunt numerele
aleatoare care vor fi generate, evoluþia algoritmului este perfect
precizatã.

<P>
<B>Definiþie:</B> O problemã de decizie este în RP dacã existã un
algoritm aleator A care ruleazã într-un timp polinomial în lungimea
instanþei (n<sup>c</sup> pentru un c oarecare), ºi care are
urmãtoarele proprietãþi:

<P>

<UL>
<LI>Dacã rãspunsul la o instanþã I este ``Da'', atunci cu o
probabilitate mai mare de 1/2 algoritmul va rãspunde ``Da''.

<P>
</LI>
<LI>Dacã rãspunsul la o instanþã I este ``Nu'', atunci cu
probabilitate 1 algoritmul va rãspunde ``Nu''.
</LI>
</UL>

<P>
De cine este datã ``probabilitatea'' de mai sus?  De numãrul de ºiruri
aleatoare.  Cînd rulãm un algoritm aleator pentru o instanþã I avem la
dispoziþie 2<sup>n<sup>c</sup></sup> ºiruri aleatoare de biþi; pentru
unele dintre ele algoritmul rãspunde ``Da'', pentru celelalte rãspunde
``Nu''.  Ceea ce facem este sã numãrãm pentru cîte ºiruri algoritmul
ar rãspunde ``da'' ºi sã facem raportul cu 2<sup>n<sup>c</sup></sup>.
Aceasta este probabilitatea ca algoritmul sã rãspundã ``da''.  Opusul
ei este probabilitatea sã rãspundã ``nu''.

<P>
O tehnicã foarte simplã de amplificare poate creºte nedefinit aceastã
probabilitate: dacã executãm algoritmul de 2 ori pe aceleaºi date de
intrare, probabilitatea de a greºi pentru rãspunsuri ``nu'' rãmîne 0.
Pe de altã parte, ajunge ca algoritmul sã rãspundã mãcar odatã ``da''
pentru a ºti cã rãspunsul este ``da'' cu siguranþã!  Din cauza asta,
dacã probabilitatea de eroare este p pentru algoritm, executînd de k
ori probabilitatea coboarã la p<sup>k</sup> (nu uitaþi ca p este
subunitar, ba chiar sub 1/2).  Aceastã metodã se numeºte ``boost'' în
englezã, ºi face dintr-un algoritm probabilist slab ca discriminare o
sculã extrem de puternicã!

<P>
Pentru a scãdea probabilitatea de eroare a unui algoritm care poate
greºi cu probabilitatea <TT>p</TT> pînã sub o limitã doritã
<TT>siguranta</TT>, se procedeazã astfel:

<P>
<PRE>
raspuns, probabilitate = nu, 1
do (raspuns = nu) and (probabilitate &gt; siguranta) -&gt;
        raspuns, probabilitate := executa(algoritm), probabilitate * p
od
</PRE>

<P>
Iatã un exemplu ºi o aplicaþie al algoritmilor aproximativi.

<P>

<H2><A NAME="SECTION00051000000000000000">
Rãdãcinile unui polinom</A>
</H2>

<P>
Fie un polinom de mai multe variabile, x<sub>1</sub>, x<sub>2</sub>,
... x<sub>n</sub>.  Acest polinom poate fi descris printr-o formulã
aritmeticã, de pildã: 
(x<sub>1</sub> + 1) (x<sub>2</sub> + 1) ... (x<sub>n</sub> + 1).
Întrebarea este: este acest polinom identic nul sau nu?

<P>
Desigur, o posibilitate este de a ``expanda'' acest polinom în formã
canonicã (sumã de produse), ºi de a compara fiecare coeficient cu
0.  Dar în general aceastã operaþie poate lua un timp exponenþial!
(De exemplu polinomul anterior genereazã 2<sup>n</sup> termeni!).

<P>
Soluþia este sã ne bazãm pe douã proprietãþi elementare ale
polinoamelor:

<P>

<UL>
<LI>Un polinom identic nul este 0 pentru orice combinaþie de valori
a variabilelor;
</LI>
<LI>Un polinom ne-nul are ``puþine'' rãdãcini într-un
corp<A NAME="tex2html6"
  HREF="#foot262"><SUP>6</SUP></A>.
</LI>
</UL>

<P>
De aici rezultã cã:

<P>

<UL>
<LI>Dacã polinomul este nul, atunci evaluarea lui în orice punct
va da 0;
</LI>
<LI>Dacã polinomul este ne-nul, atunci probabilitatea de a obþine
valoarea 0 într-un punct (v<sub>1</sub>, v<sub>2</sub>,
... v<sub>n</sub>) ales arbitrar din S<sup>n</sup> este &lt; d/|S|.
</LI>
</UL>

<P>
Pentru polinomul de mai sus gradul este n, ºi putem alege pentru
K de exemplu Z<sub>p</sub>, unde p este un numãr prim relativ mare în
raport cu n (de douã ori mai mare ajunge!).

<P>
Alegînd arbitrar numerele v<sub>1</sub>, v<sub>2</sub>, ...,
v<sub>n</sub> în Z<sub>p</sub> ºi evaluînd q(v<sub>1</sub>,
v<sub>2</sub>, ..., v<sub>n</sub>) mod p, putem imediat afirma cu 
probabilitate mare &gt; 1 - n/p despre q dacã este nul sau nu!
Observaþi cã evaluarea polinomului nu este prea costisitoare,
putîndu-se face în timp polinomial în lungimea expresiei care
descrie polinomul.

<P>
Folosind metoda de ``boost'' putem creºte rapid siguranþa noastrã
despre rezultatul algoritmului.

<P>

<H2><A NAME="SECTION00052000000000000000">
Izomorfismul arborilor</A>
</H2>

<P>
Iatã ºi o aplicaþie imediatã a acestei proprietãþi.

<P>
Se dau doi arbori, cu rãdãcina precizatã.  Sunt aceºti doi arbori
``izomorfi'' (identici prin re-ordonarea fiilor)?  Aceastã problemã
este surprinzãtor de dificilã pentru un algoritm determinist (am
impresia chiar cã este NP-completã).  Iatã însã o soluþie
aproape imediatã: construim pentru fiecare arbore cîte un polinom
care nu depinde de ordinea fiilor unui nod, în aºa fel încît dacã
ºi numai dacã arborii sunt izomorfi polinoamele sunt egale.  Apoi
pur ºi simplu testãm ca mai sus dacã polinomul diferenþã este
nul.

<P>
O metodã de a asocia recursiv un polinom unui arbore este de pildã
urmãtoarea: fiecãrui nod îi asociem o variabilã x<sub>k</sub>, unde k
este <EM>înãlþimea</EM> nodului (distanþa pînã la cea mai
depãrtatã frunzã).  Frunzele vor avea toate asociate variabila
x<sub>0</sub>.  Apoi asociem nodului v de înãlþime k cu fii v<sub>1</sub>,
... v<sub>l</sub> polinomul f<sub>v</sub> = (x<sub>k</sub> -
f<sub>v<sub>1</sub></sub>) (x<sub>k</sub> - f<sub>v<sub>2</sub></sub>)
... (x<sub>k</sub> - f<sub>v<sub>l</sub></sub>).  Se aratã uºor cã
polinoamele sunt egale pentru arbori izomorfi, bazîndu-ne pe
unicitatea descompunerii în factori a unui polinom.  Gradul
polinomului asociat unui nod este egal cu suma gradelor fiilor, care
la rîndul ei este egalã cu numãrul de frunze care se aflã sub acel nod
(cum se demonstreazã imediat prin inducþie dupã înãlþime).  ªi asta-i tot!

<P>
Pentru a încheia secþiunea, sã observãm cã singurul algoritm
eficient cunoscut pentru a verifica primalitatea unui numãr este tot
probabilist<A NAME="tex2html7"
  HREF="#foot245"><SUP>7</SUP></A>!  Pentru cã numerele prime mari stau la baza criptografiei
cu cheie publicã în sistemul RSA (probabil cel mai rãspîndit la
ora actualã), iatã cã unele dintre cele mai importante aplicaþii
se bazeazã indirect pe algoritmi probabiliºti.  Nimeni nu va putea
obiecta asupra utilitãþii lor!

<P>

<H1><A NAME="SECTION00060000000000000000">
Algoritmi on-line</A>
</H1>

<P>
Adesea trebuie luate decizii cu informaþii incomplete.  Un caz
particular este luarea de decizii pe mãsurã ce datele devin
disponibile.  Deciziile afecteazã viitorul, dar sunt luate fãrã a
avea cunoºtinþe despre datele viitoare.  Sa vedem în acþiune un
exemplu foarte simplu:

<P>

<H2><A NAME="SECTION00061000000000000000">
Problema schiorului</A>
</H2>

<P>
Se pune problema: ce este mai bine: sã închiriezi sau sã cumperi
schiuri?  (Vom presupune cã preþul schiurilor este constant de-a
lungul timpului, ca sã simplificãm problema).  Dilema constã din
faptul cã în fiecare sezon, nu ºtii dacã te vei mai duce odatã.
Dacã le cumperi ºi nu te mai duci, ai dat banii degeaba.  Dacã le
tot închiriezi ºi te duci des, s-ar putea sã le plãteºti de mai
multe ori.  Totuºi, trebuie sã iei o decizie.  Pe care?

<P>
Existã un rãspuns foarte simplu, care promite nu cã dã rezultatul
cel mai ieftin în orice circumstanþã, ci doar cã nu vei cheltui de
douã ori mai mult decît în cazul în care ai face decizia perfectã
(decizia perfectã este cea care ºtie precis dacã te vei mai duce,
ºi de cîte ori; ea nu este accesibilã decît ``post-factum'', deci
este pur teoreticã).

<P>
Algoritmul este: închiriezi schiuri pînã ai dat pe chirie costul
schiurilor.  Dupã aceea dacã mai vrei sã mergi le cumperi.  Voi
demonstra rapid cã în felul ãsta orice s-ar întîmpla nu pierzi
mai mult de jumate din banii pe care i-ai fi cheltuit în cazul ideal.

<P>
Avem 3 posibilitãþi:

<P>

<OL>
<LI>Te opreºti înainte de a le cumpãra: în cazul ãsta ai jucat
perfect, pentru cã ai schiat ºi nu puteai ieºi mai ieftin nicicum;

<P>
</LI>
<LI>Te opreºti imediat dupã ce le-ai cumpãrat.  În cazul ãsta ai
dat de douã ori preþul (odatã pe închirieri, ºi odatã pe
cumpãrare), dar ai schiat cît ai fi putut schia dînd numai odatã
preþul (mai ieftin de odatã nu puteai ieºi);

<P>
</LI>
<LI>Te opreºti mai tîrziu: în cazul ãsta cel mai ieftin era tot
sã le cumperi din prima zi, deci iar ai cheltuit dublu.
</LI>
</OL>

<P>
Orice altã schemã foloseºti pentru a decide cumpãrarea, existã un
scenariu în care poþi cheltui mai mult de dublu faþã de optim.  

<P>
Algoritmii on-line apar foarte natural într-o mulþime de situaþii:
de exemplu în reþele de calculatoare, algoritmii care decid traseul
unui pachet cu informaþii sunt algoritmi on-line; dacã decid trasee
proaste, reþeaua poate deveni supra-aglomeratã în viitor; astfel de
algoritmi nu au idee despre cererile viitoare, aºa cã acþioneazã
cu informaþie incompletã.

<P>
Un alt exemplu este în sistemele de operare: algoritmii dupã care
cache-urile (sau sistemele de memorie virtualã) aleg paginile care
trebuie înlocuite.  Alegerea aceasta nu poate fi optimã în absenþa
informaþiilor despre viitoarele cereri.  Cu toate acestea, anumite
alegeri sunt mai bune decît altele.

<P>
Un al treilea exemplu, tot din contextul sistemelor de operare, este
al algoritmilor de planificare, care trebuie sã stabileascã în ce
moment se executã fiecare proces pe un calculator (paralel).  Acolo
unde minutul de rulare costã o grãmadã de bani, deciziile trebuie
sã risipeascã cît mai puþin timp.  Însã job-uri pentru
prelucrare sosesc dinamic, aºa cã algoritmii trebuie sã facã
faþã unui mediu în continuã schimbare.

<P>
Algoritmii on-line sunt în general analizaþi comparîndu-i cu
algoritmii off-line, care ar avea înainte de a face deciziile
informaþii perfecte despre toate cererile viitoare.  Este clar cã
informaþia aceasta este un mare avantaj, aºa cã în general 
algoritmii on-line au performanþe mult mai proaste decît cei
corespunzãtori off-line.

<P>
Cercetãrile în acest domeniu sunt doar la început; se exploreazã
ºi variante de algoritmi hibrizi on/off-line, în care algoritmul are
o idee despre viitor, dar nu neapãrat o vedere completã.  Asta nu
face întotdeauna sarcina algoritmului mai simplã, pentru cã adesea
problema cu informaþie completã este NP-completã...

<P>

<H1><A NAME="SECTION00070000000000000000">
Rezumat</A>
</H1>

<P>
În acest articol am trecut razant printr-o grãmadã de probleme
fascinante.  Iatã recapitulate sumar conceptele esenþiale
întîlnite:

<P>

<UL>
<LI>Orice algoritm se exprimã folosind un set de operaþiuni
elementare;
</LI>
<LI>Un algoritm poate rezolva o instanþã a unei probleme dintr-o
clasã întreagã;
</LI>
<LI>Complexitatea algoritmilor este o funcþie de mãrimea
instanþei ºi mãsoarã operaþiile efectuate pentru a rezolva
cel mai nefavorabil caz;
</LI>
<LI>Complexitatea se exprimã concis prin ordinul de mãrime al
funcþiei complexitate spre infinit;
</LI>
<LI>Invarianþii sunt o metodã foarte utilã pentru a demonstra
corectitudinea unui algoritm;
</LI>
<LI>Complexitatea unei probleme este complexitatea celui mai rapid
algoritm care o poate rezolva;
</LI>
<LI>Existã probleme care au nevoie de un timp exponenþial (în
mãrimea problemei) sau chiar mai mult pentru a fi rezolvate; existã
probleme care nu se pot rezolva deloc cu algoritmi;
</LI>
<LI>Clasa problemelor care au algoritmi nedeterminiºti polinomiali
include foarte multe probleme practice; nimeni nu ºtie cum sã
rezolve aceste probleme în mod eficient;
</LI>
<LI>Clasa problemelor NP-complete este un set de probleme care se
rezolvã toate la fel de repede; un algoritm care ar rezolva
deterministic polinomial una din ele ar cauza rezolvarea tuturor
problemelor din NP rapid;
</LI>
<LI>Algoritmii aproximativi încearcã sã gãseascã mai repede
soluþii sub-optimale la probleme grele;
</LI>
<LI>Algoritmii aleatori folosesc aleatorismul pentru a forþa
comportarea unor probleme mai curînd ca în cazul mediu decît ca în
cazul cel mai rãu;
</LI>
<LI>Algoritmii probabiliºti gãsesc soluþiile cu mare
probabilitate, dar nu întotdeauna, însã o fac repede;
</LI>
<LI>Algoritmii on-line trebuie sã ia decizii înainte de a avea
toate informaþiile disponibile;
</LI>
<LI>Multe domenii practice beneficiazã masiv de noile tehnici, cea
mai notabilã fiind criptografia.
</LI>
</UL>

<P>
<BR><HR><H4>Footnotes</H4>
<DL>
<DT><A NAME="foot170">...<IMG
 WIDTH="18" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img28.png"
 ALT="$\Omega$"></A><A NAME="foot170"
 HREF="algoritmi-html.html#tex2html1"><SUP>1</SUP></A>
<DD>Mai exact <!-- MATH
 $f \in \Omega(g)
\Leftrightarrow f \in O(g) \land g \in O(f)$
 -->
<IMG
 WIDTH="255" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img29.png"
 ALT="$f \in \Omega(g)
\Leftrightarrow f \in O(g) \land g \in O(f)$">.

<DT><A NAME="foot261">... egale</A><A NAME="foot261"
 HREF="algoritmi-html.html#tex2html2"><SUP>2</SUP></A>
<DD>Problema este
într-adevãr NP-completã, dacã socotim ca mãrime de intrare
 <EM>lungimea</EM> tuturor numerelor în biþi; altfel existã un
 algoritm de programare dinamicã de complexitate S n, unde S este suma 
numerelor, iar n este numãrul de numere.  Observaþi însã cã S
este exponenþialã în lungimea numerelor.

<DT><A NAME="foot204">...
NP-complete</A><A NAME="foot204"
 HREF="algoritmi-html.html#tex2html3"><SUP>3</SUP></A>
<DD>Cititorul atent va observa cã noþiunea de
NP-completitudine a fost definitã numai pentru probleme de decizie:
cu rãspuns Da/Nu, pe cînd problemele de optimizare au în general un
rãspuns numeric; cititorul poate însã sã fie liniºtit, pentru cã
putem re-formula o problemã de optimizare ca o problemã de decizie:
în loc de ``care este drumul minim?'', întrebãm ``nu-i aºa cã
existã un drum mai scurt de 100?''.

<DT><A NAME="foot216">... grafuri</A><A NAME="foot216"
 HREF="algoritmi-html.html#tex2html4"><SUP>4</SUP></A>
<DD>O cuplare este un set de muchii care nu are
vîrfuri comune, iar o cuplare maximalã este una care are un numãr
maxim de muchii.

<DT><A NAME="foot221">... rele</A><A NAME="foot221"
 HREF="algoritmi-html.html#tex2html5"><SUP>5</SUP></A>
<DD>Numãrul de
instanþe rele poate fi estimat din distribuþia variabilei aleatoare
complexitate, ºi este într-adevãr mic.

<DT><A NAME="foot262">...
corp</A><A NAME="foot262"
 HREF="algoritmi-html.html#tex2html6"><SUP>6</SUP></A>
<DD>Aceasta este Teorema Lipton-Schwartz-Zippel: fie <IMG
 WIDTH="57" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img90.png"
 ALT="$S
\subseteq K$"> o submulþime a unui corp K, iar <!-- MATH
 $q(\overline{x})$
 -->
<IMG
 WIDTH="38" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img91.png"
 ALT="$q(\overline{x})$"> un
polinom de n variabile de grad d cu coeficienþi în K.  Atunci
ecuaþia <!-- MATH
 $q(\overline{x}) = 0$
 -->
<IMG
 WIDTH="70" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.png"
 ALT="$q(\overline{x}) = 0$"> are cel mult d |S|<sup>n-1</sup> soluþii în
S.

<DT><A NAME="foot245">...
probabilist</A><A NAME="foot245"
 HREF="algoritmi-html.html#tex2html7"><SUP>7</SUP></A>
<DD>Aºa se genereazã numere prime: se genereazã un
numãr aleator ºi se verificã primalitatea cu un astfel de
algoritm.

</DL>
<BR><HR>

</BODY>
</HTML>
