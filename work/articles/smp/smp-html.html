<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//RO">

<!--Converted with LaTeX2HTML 2K.1beta (1.47)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Multiprocesoare simetrice: coerenþa cache-urilor Seria: arhitectura modernã a calculatoarelor</TITLE>
<META NAME="description" CONTENT="Multiprocesoare simetrice: coerenþa cache-urilor Seria: arhitectura modernã a calculatoarelor">
<META NAME="keywords" CONTENT="smp-html">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-2">
<META NAME="Generator" CONTENT="LaTeX2HTML v2K.1beta">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="../articles.css">

</HEAD>

<BODY >

<P>

<P>
<H1 ALIGN="CENTER">Multiprocesoare simetrice: coerenþa cache-urilor 
<BR>
Seria: arhitectura modernã a calculatoarelor</H1>
<P ALIGN="CENTER"><STRONG>Mihai Budiu -- <TT>mihaib+@cs.cmu.edu</TT> 
<BR><TT>http://www.cs.cmu.edu/~mihaib/</TT></STRONG></P>
<P ALIGN="CENTER"><STRONG>octombrie 1998</STRONG></P>

<P>
<DL>
<DT><STRONG>Subiect:</STRONG></DT>
<DD>cum se implementeazã coerenþa cache-urilor în
maºinile multiprocesor
</DD>
<DT><STRONG>Cunoºtinþe necesare:</STRONG></DT>
<DD>cache, programare în limbaj maºinã,
noþiuni elementare despre arhitectura calculatoarelor
</DD>
<DT><STRONG>Cuvinte cheie:</STRONG></DT>
<DD>multiprocesoare simetrice, coerenþã, cache,
atomat finit
</DD>
</DL>

<P>
<BR>

<H2><A NAME="SECTION00010000000000000000">
Contents</A>
</H2>
<!--Table of Contents-->

<UL>
<LI><A NAME="tex2html23"
  HREF="smp-html.html">Paralelism ºi performanþã</A>
<LI><A NAME="tex2html24"
  HREF="#SECTION00030000000000000000">Multiprocesoare</A>
<LI><A NAME="tex2html25"
  HREF="#SECTION00040000000000000000">Cache-uri</A>
<UL>
<LI><A NAME="tex2html26"
  HREF="#SECTION00041000000000000000">Problema coerenþei</A>
</UL>
<BR>
<LI><A NAME="tex2html27"
  HREF="#SECTION00050000000000000000">Un protocol bazat pe ascultarea magistralei</A>
<LI><A NAME="tex2html28"
  HREF="#SECTION00060000000000000000">Detaliile protocolului</A>
<UL>
<LI><A NAME="tex2html29"
  HREF="#SECTION00061000000000000000">Semnalele</A>
<LI><A NAME="tex2html30"
  HREF="#SECTION00062000000000000000">Starea blocului</A>
<LI><A NAME="tex2html31"
  HREF="#SECTION00063000000000000000">Operaþiile pe magistralã</A>
<LI><A NAME="tex2html32"
  HREF="#SECTION00064000000000000000">Comunicaþia</A>
<LI><A NAME="tex2html33"
  HREF="#SECTION00065000000000000000">Automatul finit al bus-master-ului</A>
<LI><A NAME="tex2html34"
  HREF="#SECTION00066000000000000000">Automatul finit al unui cache non-master</A>
</UL>
<BR>
<LI><A NAME="tex2html35"
  HREF="#SECTION00070000000000000000">Corectitudine</A>
<LI><A NAME="tex2html36"
  HREF="#SECTION00080000000000000000">Un exemplu: SGI Challenge</A>
</UL>
<!--End of Table of Contents-->
<P>
<BR>
<BR>
<BR>

<P>
În ultimele numere din PC Report am vãzut o serie de articole
deosebit de interesante despre arhitectura internã a unor procesoare
moderne (Pentium, AMD K6, etc.).  Articolele erau bine documentate,
ºi prezentau o cantitate impresionantã de informaþii într-un
spaþiu mai curînd restrîns.  Ca atare mi-am propus sã scriu o
întreagã serie de articole numite generic ``arhitectura modernã a
calculatoarelor'' în care sã explic pe îndelete noþiunile
esenþiale care apar în proiectarea acestor bijuterii tehnologice.
Voi încerca pe rînd sã ``demistific'' noþiuni ca ``superscalar'',
``pipelined'', ``staþie de rezervare'', ``paralelism la nivel de
instrucþiune'', ``multiprocesoare simetrice'', ``redenumirea
regiºtrilor'', ``forwarding'', ``protocol de coerenþã'',
``predicþia salturilor'', ``execuþie speculativã'',
``prefetching'', etc.

<P>
Adevãrul este cã în ultimii 10 ani arhitectura calculatoarelor a
suferit niºte modificãri uriaºe.  În urmã cu 20 de ani gama de
putere ºi preþ ale calculatoarelor avea extreme foarte
îndepãrtate; PCul era o jucãrioarã în comparaþie cu staþiile de
lucru, care la rîndul lor erau puse în umbrã de ``mainframes''; la
vîrful ierarhiei tronau supercalculatoarele.  Cu fiecare an trecut,
extremele s-au apropiat simþitor; practic toate firmele care fãceau
numai supercalculatoare au dat faliment<A NAME="tex2html1"
  HREF="#foot51"><SUP>1</SUP></A>, iar diferenþele între puterea de calcul a unui PC ºi a
unei staþii de lucru s-au redus enorm; idei care se foloseau pe
vremuri în proiectarea supercalculatoarelor sunt acum în mod comun
implementate în procesoarele PCurilor de pe biroul fiecãruia.
Complexitatea design-urilor ºi ingeniozitatea soluþiilor sunt extrem
de surprinzãtoare pentru cel care nu a rãmas la curent cu evoluþia
domeniului fie ºi pentru puþinã vreme.

<P>
Complexitatea aparatelor este uriaºã, iar viteza cu care apar
inovaþiile depãºeºte cu mult viteza cu care pot tasta eu texte,
aºa cã nu voi putea face decît o ilustrare a conceptelor
esenþiale, care sper sã poatã da o idee generalã despre anatomia
unui calculator contemporan.

<P>
Prima tema pe care mi-am ales-o are de-a face cu arhitectura
calculatoarelor cu mai multe procesoare; din spectrul larg de
implementãri (despre care vorbesc pe scurt în
secþiunea&nbsp;<A HREF="smp-html.html#multiprocesoare">2</A>) voi ataca o singurã opþiune, dar
care este dominantã economic: cea a multiprocesoarelor simetrice cu
memorie partajatã bazate pe o magistralã comunã.

<P>

<H1><A NAME="SECTION00020000000000000000">
Paralelism ºi performanþã</A>
</H1>

<P>
De vreo douãzeci de ani încoace se prezice moartea paradigmei
arhitecturale numitã ``von Neumann'', a calculatoarelor cu un singur
procesor ºi o unitate de memorie.  Unii experþi se
încãpãþîneazã sã prezicã plafonarea performanþelor sistemelor
bazate pe astfel de arhitecturi, iar fabricanþii de sisteme se
încãpãþîneazã sã contrazicã prin sistemele construite
predicþiile sumbre.  În trecere vreau sã observ cã numele
``arhitecturã von Neumann'', folosit adesea peiorativ pentru a indica
o arhitecturã depãºitã, nu este întru totul potrivit; John von
Neumann, care a murit în 1956, a fost conºtient pe deplin de
importanþa paralelismului; a ºi scris niºte cãrþi foarte
interesante pe tema asta; von Neumann însã era un inginer
extraordinar (de fapt era profesor de matematicã la Princeton, cu o
diplomã în inginerie chimicã de la universitatea din Budapesta, dar
nu o sã ne incomodeze astfel de distincþii din a-l trata drept
``inginer''), ºi a realizat cã pentru a rezolva problemele ele
trebuie adesea simplificate, sparte în bucãþi mai mici care sunt
apoi tratate independent.  Starea catastrofalã a componentelor
electronice disponibile pe vremea aceea (relativ la ziua de azi)
fãcea proiectarea ºi întreþinerea unui sistem atît de complex ca
un calculator o sarcinã supraomeneascã, aºa cã von Neumann a
fãcut problema tractabilã ºi a rezolvat-o cu atît de mult succes
încît ºi acum, dupã 50 de ani, organizarea propusã de el este
dominantã.

<P>
Oricum, fie cã se plafoneazã sau nu performanþele unui
microprocesor, sã ai mai multe nu poate sã strice prea tare, nu?
Unde-s mai multe capete se gîndeºte mai bine.  Cã lucrurile nu stau
întotdeauna aºa reiese din urmãtoarea întrebare: ``dacã un ins
sapã o groapã în 60 de secunde, 60 de inºi sapã o groapã într-o
secundã?''  E (aproape) clar cã nu orice poate fi rezolvat în
paralel cu eficacitate.  Asupra consecinþelor acestui enunþ, care
sunt exprimate ºi de celebra lege a lui Amdahl, vom reveni în alte
articole.

<P>
Oricum, anumite activitãþi se pot într-adevãr face relativ repede
dacã avem mai multe resurse computaþionale la-ndemînã.  De
exemplu, într-o întreagã suitã de articole despre sistemele de
operare, am observat cã sistemele de operare moderne permit executarea
simultanã a mai multor programe printr-un mecanism simplu numit
time-sharing, care constã în executarea întreþesutã a grupe de
instrucþiuni din programe diferite (adicã programul 1 merge 10
milisecunde, dupã care programul 2 10 milisecunde, etc.).  Dacã avem
mai multe procesoare, atunci putem executa cu adevãrat mai multe
programe deodatã: cîte unul pe fiecare procesor.

<P>

<H1><A NAME="SECTION00030000000000000000">
Multiprocesoare</A>
</H1>&nbsp;<A NAME="multiprocesoare"></A>
<P>
Existã mai multe feluri de maºini cu mai multe procesoare, dar noi
ne vom ocupa de unul singur în acest articol.  Celelalte variante
meritã desigur menþiune; sã le-o dãm.

<P>
Putem împãrþi multiprocesoarele în douã mari categorii, care
diferã din modul în care se acceseazã memoria în care se aflã
programele ºi datele.

<P>

<UL>
<LI>Prima variantã pune toate procesoarele la un loc, ca
utilizatoare ale unei singure memorii.  Aceste sisteme se numesc cu
memorie partajatã (<EM>shared memory</EM>).

<P>
Existã douã feluri mari de sisteme cu memorie partajatã:

<P>

<UL>
<LI>Sisteme cu acces uniform la memorie (UMA, <EM>uniform memory
access</EM>): dacã oricare ar fi sursa ºi destinaþia unui cuvînt de
date accesat timpul este cam acelaºi.  Noi vom vorbi în acest
articol despre o clasã de maºini UMA numite multiprocesoare
simetrice (SMP: <EM>Symmetric Multi-Processors</EM>).  Vom vedea imediat
de ce se numesc aºa.

<P>
</LI>
<LI>A doua variantã se numeºte NUMA: de la ne-uniform.  În astfel
de sisteme fiecare procesor are propria lui memorie la care poate
ajunge repede, iar accesul la memoria altuia ia ceva mai mult timp.
</LI>
</UL>

<P>
</LI>
<LI>În fine, avem sistemele la care un procesor nu poate accesa
nicicum memoria altuia, iar comunicaþia între procesoare se face
prin mesaje (<EM>message passing</EM>).
</LI>
</UL>

<P>
Trebuie spus cã tipul în care se încadreazã o maºinã depinde
foarte mult de nivelul la care o privim.  De pildã dacã luãm o
colecþie de staþii de lucru, la nivel hardware acestea categoric
comunicã prin mesaje.  Pe de altã parte putem instala pe ele un
nivel software (cum ar fi de pildã sistemul de operare Mach), care
folosind tehnici de memorie virtualã permite maºinilor sã partajeze
un acelaºi spaþiu de adrese virtual, astfel încît ce scrie o
maºina la adresa 5 celelalte pot citi de la adresa 5; în cazul ãsta
maºinile au ceea ce se numeºte memorie distribuitã partajatã (DSM:
<EM>Distributed Shared Memory</EM>), care este un tip de NUMA.

<P>
Un alt exemplu despre fragilitatea clasificãrii: chiar maºinile
cãrora acest articol le este dedicat, multiprocesoarele simetrice,
sunt categorisite drept maºini UMA.  Dar vom vedea cã fiecare
procesor dintr-un sistem SMP are de fapt un cache (o memorie localã
micã), la care accesul este mult mai rapid decît la memoria globalã
a sistemului; la acest nivel maºina aratã de fapt ca o NUMA...

<P>
O maºinã cu mai multe procesoare se numeºte ``simetricã'' dacã
toate procesoarele au roluri egale: fiecare procesor poate executa
orice tip de cod.  Prin contrast, maºinile asimetrice dedicã anumite
procesoare anumitor treburi, cum ar fi executarea codului
întreruperilor, executarea codului sistemului de operare, etc.  Pe
noi ne vor interesa procesoarele simetrice pentru cã sunt cele mai
reprezentate în maºinile comerciale; existã ºi PCuri cu 2 sau 4
procesoare Pentium.

<P>
În fine, vom mai disocia calculatoarele cu memorie partajatã în
douã categorii distincte, dupã felul în care ajung la memorie.
Tipul care ne va interesa, ºi din care cele mai multe maºini SMP fac
parte, este cel al maºinilor bazate pe o magistralã comunã (bus):
toate procesoarele pun cererile de acces la memorie pe o singurã
sîrmã.  Vom vedea cã acesta este un factor crucial.  PCurile SMP
sunt de acest tip, ca ºi cele mai multe maºini comerciale (staþiile
ULTRASparc, SGI Challenge, etc.)

<P>
Pe de altã parte, existã maºini care au o reþea de interconectare
<EM>interconnection network</EM> între procesoare ºi (de obicei
multiplele) module de memorie.

<P>
<PRE>
sistem bazat pe magistrala comuna     sistem bazat pe retea de interconectare  
     -----------                              ------------------ 
     | memorie |                              |    retea de    | 
     -----------                              | interconectare | 
          ||                                  ------------------ 
     ===========   magistrala                    |    |    | 
     |    |    |                                ---- ---- ----
    ---- ---- ----                              |m1| |m2| |m3| memorie locala
    |c1| |c2| |c3| cacheuri                     ---- ---- ---- 
    ---- ---- ----                               |    |    | 
     |    |    |                                ---- ---- ---- 
    ---- ---- ----                              |c1| |c2| |c3| cacheuri 
    |p1| |p2| |p3| procesoare                   ---- ---- ---- 
    ---- ---- ----                               |    |    | 
                                                ---- ---- ---- 
                                                |p1| |p2| |p3| procesoare 
                                                ---- ---- ----
</PRE>

<P>
Diferenþa esenþialã este de <EM>scalabilitate</EM>: este extrem de
greu de construit o maºinã bazatã pe bus cu multe procesoare, din
cauzã cã, aºa cum e uºor de imaginat, de de la un anumit numãr de
procesoare încolo bus-ul devine factorul care limiteazã viteza de
comunicare.  

<P>
Pe de altã parte, maºinile cu reþea de interconectare pot creºte
mai bine, pînã la sute sau chiar mii de procesoare (maºina IBM care l-a
bãtut pe Kasparov, un SP2, e bazatã pe o reþea care
interconecteazã pînã la o mie de procesoare).

<P>
Trebuie spus cã multiprocesoarele sunt încã departe de a fi
panaceul universal în a rezolva probleme computaþionale dificile,
mai ales din cauzã cã scrierea de programe pentru astfel de maºini
este extrem de dificilã.  Oricum, cercetarea în domeniu este în
continuare febrilã, ºi o mulþime de schimbãri revoluþionare
aºteaptã probabil la cotiturã.

<P>

<H1><A NAME="SECTION00040000000000000000">
Cache-uri</A>
</H1>

<P>
Chiar dacã avem un singur procesor, viteza de rãspuns a unei memorii
DRAM este de vreo 15 ori mai micã decît viteza cu care procesorul
doreºte date ºi instrucþiuni, iar disparitatea de vitezã tinde sã
creascã.  Din cauza aceasta fiecare procesor modern este echipat cu o
memorie SRAM rapidã, plasatã foarte aproape de procesor, numitã cache.
(SRAMul este mult mai scump decît DRAMul; pentru acest motiv nu
înlocuim tot DRAMul cu SRAM.)  Despre cache am scris cel puþin douã
articole în PC Report: <a
href="http://www.cs.cmu.edu/~mihaib/articles/articles.html#cache">unul</a>
în martie 1997 ºi <a
href="http://www.cs.cmu.edu/~mihaib/articles/articles.html#masuri">unul</a>
luna trecutã, în octombrie 1998.  Dacã nu aveþi revistele sunteþi
bineveniþi sã luaþi articolele din pagina mea de web.  Cu toate astea
vom vedea cã subiectul nu a fost epuizat, pentru cã miezul acestui
articol tot despre cache-uri va vorbi.

<P>
Ideea de bazã este relativ simplã: programele au nevoie foarte rar
de o cantitate mare de date sau instrucþiuni simultan; ele tind sã
refoloseascã de mai multe ori o cantitate relativ micã de date.
Aceastã proprietate, verificatã empiric, se numeºte ``localitate''.
Din cauza asta un cache este util: dacã cuprinde toate datele
necesare, sau mãcar o mare parte dintre ele, atunci eficienþa
creºte simþitor, pentru cã timpul mediu de acces este redus simþitor.

<P>
Procesoarele dintr-un sistem SMP nu fac excepþie: fiecare este
echipat cu un cache (sau chiar douã, de mãrimi diferite, unul fiind
mai mare ºi mai lent).

<P>

<H2><A NAME="SECTION00041000000000000000">
Problema coerenþei</A>
</H2>

<P>
Toate bune ºi frumoase, aparent: în loc sã punem un procesor pe
magistralã punem douã, ºi maºina merge de douã ori mai repede.
Hopa, sã nu ne grãbim.  O grãmadã de probleme urîte apar de
îndatã.

<P>
Sã luãm un exemplu simplu, în care douã procesoare acceseazã
aceeaºi adresã de memorie.  Iatã o posibilã evoluþie în timp:

<P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="CENTER" COLSPAN=2>Instrucþiune</TD>
<TD ALIGN="CENTER" COLSPAN=2>cache</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
</TR>
<TR><TD ALIGN="LEFT">Timp</TD>
<TD ALIGN="LEFT">Procesor 1</TD>
<TD ALIGN="LEFT">Procesor 2</TD>
<TD ALIGN="LEFT">Procesor 1</TD>
<TD ALIGN="LEFT">Procesor 2</TD>
<TD ALIGN="LEFT">Memorie</TD>
</TR>
<TR><TD ALIGN="LEFT">0</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">mem[5]=3</TD>
</TR>
<TR><TD ALIGN="LEFT">1</TD>
<TD ALIGN="LEFT">read 5</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">cache[5]=3</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">mem[5]=3</TD>
</TR>
<TR><TD ALIGN="LEFT">2</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">read 5</TD>
<TD ALIGN="LEFT">cache[5]=3</TD>
<TD ALIGN="LEFT">cache[5]=3</TD>
<TD ALIGN="LEFT">mem[5]=3</TD>
</TR>
<TR><TD ALIGN="LEFT">3</TD>
<TD ALIGN="LEFT">write 5, 4</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">cache[5]=4</TD>
<TD ALIGN="LEFT">cache[5]=3</TD>
<TD ALIGN="LEFT">mem[5]=3</TD>
</TR>
<TR><TD ALIGN="LEFT">4</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">write  5,2</TD>
<TD ALIGN="LEFT">cache[5]=4</TD>
<TD ALIGN="LEFT">cache[5]=2</TD>
<TD ALIGN="LEFT">mem[5]=3</TD>
</TR>
</TABLE>
</DIV>

<P>
Avem acum nu mai puþin de 3 valori diferite pentru adresa 5: un 4 în
cache-ul procesorului 1, un 2 la procesorul 2 ºi 3 în memoria
însãºi.  Noi am pus procesoarele la aceeaºi memorie tocmai ca sã
poatã comunica mai uºor; dacã vroiam izolare foloseam douã
calculatoare.  Care este acum de fapt conþinutul real al adresei 5?
Cache-urile au devenit <EM>ne-coerente</EM>.

<P>
Trebuie menþionat cã problema coerenþei nu apare numai în
sistemele SMP; ea apare la o mulþime de nivele în proiectarea
sistemelor, oricînd avem de-a face cu <EM>replicarea</EM> (copierea)
informaþiei; ea apare de exemplu cînd avem de-a face cu replicarea
unor servere de web, sau cu sisteme de fiºiere în reþea (Network
File System, Andrew File System, etc), sau în oricare sistemele cu un
singur procesor atunci cînd un alt controler de magistralã (de
pildã discul) acceseazã memoria prin acces direct (<EM>DMA: Direct
Memory Access</EM>).

<P>
Problema aceasta apare de îndatã ce cineva poate modifica o copie a
datelor; problema este cã celelalte copii vor avea valori diferite.
Din cauza asta trebuie luate mãsuri speciale ca celelalte valori sã
fie aduse la zi imediat.  Orice întîrziere se poate solda cu efecte
bizare pentru programator, care se aºteaptã ca efectele execuþiei
unei instrucþiuni sã fie imediat vizibile.

<P>
Deºi problema pare relativ simplã, existã zeci de soluþii foarte
diferite calitativ, fiecare cu avantajele ºi dezavantajele ei.  Ele
diferã prin complexitatea implementãrii în hardware, prin gradul de
scalabilitate (cît de bine se pot implementa pentru maºini cu mai
multe procesoare), prin modul în care se manifestã pentru
programator, prin gradul de performanþã pe care îl oferã.

<P>
Interesant este cã soluþiile cele mai economice din punct de vedere
al impactului administrativ (overhead) cer colaborarea explicitã a
programatorului ºi oferã o vedere puþin bizarã asupra memoriei.
În acest articol vom vedea însã o soluþie relativ ``simplã''.

<P>

<H1><A NAME="SECTION00050000000000000000">
Un protocol bazat pe ascultarea magistralei</A>
</H1>

<P>
Acum vom vedea cum multiprocesoarele simetrice bazate pe o magistralã
comunã reuºesc sã sincronizeze cache-urile.  Faptul cã avem o
singurã magistralã pentru toate procesoarele este crucial.  Iatã de
ce: orice transfer de date între memorie ºi un cache se va petrece
pe magistralã.  Magistrala este din punct de vedere electric un
singur circuit, conectat la toate cache-urile.  Astfel, atunci cînd
procesorul 1 aduce cuvîntul 5 din memorie în cache-ul sãu local,
transferul se desfãºoarã pe magistralã ºi toatã lumea vede acest
lucru.  Celelalte procesoare vor ºti deci cã o copie a cuvîntului 5
se aflã la procesorul 1, aºa cã atunci cînd vor dori sã o
modifice vor negocia cu acesta.

<P>
Pentru cã fiecare cache se uitã la magistralã ºi atunci cînd
alþii discutã, acest gen de protocoale se numesc ``snoopy
bus-based''.  ``To snoop'' înseamnã ``a-ºi bãga nasul în
treburile altora'', adicã exact ceea ce se întîmplã.

<P>
Ca sã înþelegem avantajul schemei, sã ne gîndim la schema
alternativã, care foloseºte o reþea de interconectare.  Cînd
procesorul P1 ia ceva din memorie, aceastã tranzacþie nu este
vizibilã pentru nimeni altcineva.  Asta înseamnã cã P2 o sã
trebuiascã sã afle acest lucru (de la memorie) abia cînd încearcã
sã acceseze acelaºi obiect, ºi abia dupã aceea poate sã iniþieze
negocierea cu P1.

<P>
Perfect; avem un mecanism extrem de ieftin pentru a strînge
informaþii despre plasamentul datelor (trasul cu urechea).  Acum mai
trebuie sã punem la punct un protocol care sã foloseascã aceastã
informaþie.

<P>
Problema centralã sunt scrierile; atunci cînd vrem sã modificãm o
valoare, ca sã garantãm consistenþa, trebuie sã fim siguri cã nu
mai existã alte copii care dupã modificare vor avea valori diferite.
(Soluþia de a modifica toate copiile simultan pune mari dificultãþi
tehnice.)  Ce vom face: atunci cînd vrem sã scriem la adresa 5, vom
face în aºa fel încît nimeni altcineva sã nu mai aibã o copie a
datelor de acolo.  Din cauzã cã am fãcut ``snoop'' ºtim precis
cine are copii; ceea ce avem de fãcut este sã rugãm pe toþi
aceºtia sã <EM>invalideze</EM> copiile lor, scoþîndu-le din cache.
Cînd nimeni nu mai are o copie, luãm noi una, pe care o putem
modifica apoi în deplinã siguranþã.

<P>

<H1><A NAME="SECTION00060000000000000000">
Detaliile protocolului</A>
</H1>

<P>
Chiar dacã lucrurile par simple, pînã la o implementare completã
ºi corectã mai sunt mulþi paºi de fãcut, ºi chiar multe alegeri.
Noi o sã dãm o anumitã posibilã implementare, ºi o sã indicãm
pe alocuri unde sunt posibile variaþiuni.  Vom fi relativ compleþi
în detalii, în aºa fel încît un arhitect sã poatã implementa
în mod neambiguu din descrierea noastrã un sistem.

<P>

<H4><A NAME="SECTION00060010000000000000">
Tipul de cache:</A>
</H4> fiecare procesor va avea un cache
<EM>write-back</EM>.  Asta înseamnã cã atunci cînd procesorul scrie
date, valoarea modificatã rãmîne în cache ºi nu este trimisã
spre memorie.  (Varianta alternativã, <EM>write-through</EM> ar utiliza
magistrala, ºi aºa supra-încãrcatã, la fiecare scriere, pentru a
trimite datele în memorie.)

<P>

<H4><A NAME="SECTION00060020000000000000">
Bus master:</A>
</H4> În fiecare clipã un singur cache va avea
dreptul de a folosi magistrala.  Dacã douã procesoare simultan
gãsesc datele în cache-urile proprii, atunci ele pot continua
execuþia în paralel.  Dacã însã amîndouã vor sã acceseze
memoria, atunci unul dintre ele va trebui sã aºtepte pînã
celãlalt terminã.  Regula dupã care se decide cine are dreptul sã
foloseascã magistrala se numeºte <EM>arbitrarea magistralei</EM>;
existã mai multe protocoale pentru asta, dar, pentru a nu ne îneca
în detalii, nu o sã discutãm despre cum se face asta.

<P>

<H4><A NAME="SECTION00060030000000000000">
Copiile datelor:</A>
</H4> Fiecare informaþie din memorie se poate
afla simultan în mai multe cache-uri, dacã nu este modificatã; o
informaþie care are mai multe copii <EM>nici nu poate fi
modificatã</EM> (e ``read-only'').  Dacã cineva vrea sã modifice o
valoare, trebuie sã obþinã o copie <EM>exclusivã</EM>.  Odatã
obþinutã o astfel de copie, dupã modificare valoarea este marcatã
ca ``murdãritã'' (<EM>dirty</EM>).

<P>

<H4><A NAME="SECTION00060040000000000000">
Propagarea copiilor:</A>
</H4> Dacã un cache doreºte sã obþinã
o copie, o sã facã o cerere pe magistralã.  Memoria va oferi datele
dacã acestea sunt ``curate'', altfel ele vor veni de la cache-ul
posesor.  Cînd niºte date ``murdare'' sunt copiate la un alt
procesor, ele sunt copiate ºi în memorie, ºi devin apoi ``curate''.

<P>

<H2><A NAME="SECTION00061000000000000000">
Semnalele</A>
</H2>

<P>
Sã facem o schemã care aratã cum vor comunica procesorul, cache-ul
ºi magistrala.  Fiecare sãgeatã aratã direcþia în care
informaþia este transportatã.

<P>
<PRE>
                                  cache
    ________     adresa     _________________               | m |
   |        |-------------&gt;|adresa stare date|  operatie    | a |
   |        |     date     |-----------------|-------------&gt;| g |
   |procesor|&lt;------------&gt;|  1    curat   3 |   adresa     | i |
   |        | scrie/citeste|  2    murdar  2 |-------------&gt;| s |
   |        |-------------&gt;|  3   invalid  - |    date      | t |
   |        | gata / blocat|                 |&lt;------------&gt;| r |
   |________|&lt;-------------|_________________|              | a |
                                                            | l |
                                                            | a |
</PRE>

<P>

<H2><A NAME="SECTION00062000000000000000">
Starea blocului</A>
</H2>

<P>
Aºa cum indicã ºi desenul anterior, fiecare bloc dintr-un cache va
fi într-una din urmãtoarele stãri:

<P>
<DL>
<DT><STRONG>Curat:</STRONG></DT>
<DD>valoarea din bloc este validã ºi nu poate fi
modificatã de posesor; aceeaºi valoare se aflã în memoria
principalã, ºi poate ºi în alte cache-uri;
</DD>
<DT><STRONG>Murdar:</STRONG></DT>
<DD>blocul este modificat de procesorul curent, ºi nu
existã nici o altã copie a sa; valoarea din memorie nu este
corectã;
</DD>
<DT><STRONG>Invalid:</STRONG></DT>
<DD>acest bloc nu se gãseºte de loc în cache.
</DD>
</DL>

<P>

<H2><A NAME="SECTION00063000000000000000">
Operaþiile pe magistralã</A>
</H2>

<P>
Cînd un procesor devine master de magistralã, comanda lansatã de
acesta va fi pusã pe magistralã ºi observatã de toatã lumea.
Vom presupune cã din clipa în care un procesor devine master de
magistralã el rãmîne astfel pînã cînd tranzacþia doritã de el
a fost terminatã.  Aceastã presupunere este destul de restrictivã
pentru sistemele reale, în care timpul de reacþie al memoriei poate
fi de sute de cicli; un sistem real complicat va permite executarea
operaþiilor în douã faze diferite, cerere-rãspuns (astfel de
operaþii se numesc <EM>split-transaction</EM>: tranzacþie despicatã,
din motive evidente).  Din pãcate protocoalele cu tranzacþii
despicate devin extrem de complicate, mai ales dacã vrem sã ne
asigurãm de corectitudinea lor.

<P>
Pe magistralã se poate afla una din urmãtoarele cereri:

<P>
<DL>
<DT><STRONG>Citeºte:</STRONG></DT>
<DD>procesorul vrea sã citeascã o copie ne-exclusivã;
</DD>
<DT><STRONG>Scrie:</STRONG></DT>
<DD>unicul procesor care posedã un bloc murdar trimite
valoarea lui spre memorie (sau/ºi un alt cache);
</DD>
<DT><STRONG>Invalideazã:</STRONG></DT>
<DD>masterul vrea sã modifice blocul indicat; pentru
aceasta roagã pe toatã lumea care are o copie sã o invalideze, iar
pe eventualul posesor exclusiv sã scrie valoarea copiei sale.
</DD>
</DL>

<P>

<H2><A NAME="SECTION00064000000000000000">
Comunicaþia</A>
</H2>

<P>
Vom folosi urmãtorul tabel cu 7 linii pentru a indica semnalele care
circulã de la/spre un cache:

<P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">Cine iniþiazã operaþia</TD>
<TD ALIGN="CENTER">procesor / bus</TD>
</TR>
<TR><TD ALIGN="LEFT">Operaþia cerutã</TD>
<TD ALIGN="CENTER">citire / scriere / invalidare</TD>
</TR>
<TR><TD ALIGN="LEFT">Este blocul cerut în cache</TD>
<TD ALIGN="CENTER">da / nu</TD>
</TR>
<TR><TD ALIGN="LEFT">Operaþia executatã pe bus</TD>
<TD ALIGN="CENTER">citire / scriere / nimic / invalidare</TD>
</TR>
<TR><TD ALIGN="LEFT">Datele aflate pe bus</TD>
<TD ALIGN="CENTER">adresa</TD>
</TR>
<TR><TD ALIGN="LEFT">Modificarea în cache-ul local</TD>
<TD ALIGN="CENTER">adresa</TD>
</TR>
<TR><TD ALIGN="LEFT">Ce face procesorul local</TD>
<TD ALIGN="CENTER">citeºte / scrie / blocat</TD>
</TR>
</TABLE>
</DIV>

<P>
Primele trei rînduri descriu o cerere care soseºte la un cache;
urmãtoarele 4 rînduri indicã cum acea cerere este executatã de
cãtre un cache.  Figurile care urmeazã conþin astfel de tabele, dar
numai coloana a doua.

<P>

<H2><A NAME="SECTION00065000000000000000">
Automatul finit al bus-master-ului</A>
</H2>

<P>
Dificultatea proiectãrii unui astfel de sistem este mare din cauzã
cã trebuie sã descriem ce face fiecare pãrticicã avînd la
dispoziþie numai informaþia vizibilã acelei pãrticele.  Noi, ca
proiectanþi, putem ``vedea'' sistemul în ansamblul sãu, dar un
cache nu poate sã vadã decît sîrmele cu care e conectat; cacheul 1
nu are nici cea mai micã idee despre conþinutul lui 2 (înafarã de
ceea ce a inferat pe parcurs).

<P>
Modul în care se descrie comportarea fiecãrei entitãþi este
folosind <EM>un automat finit</EM>.  Noi vom construi automatul finit al
unui cache, care aratã exact ce acþiune trebuie acesta sã facã ca
rãspuns la fiecare stimul venit din afarã.

<P>
Un automat finit este o colecþie de <EM>stãri</EM>, în care circuitul
se poate afla la un moment dat.  Voi indica în desene stãrile prin
cerculeþe.  Între stãri existã sãgeþi numite <EM>tranziþii</EM>.
Fiecare tranziþie este etichetatã cu o tabelã ca cea de mai sus;
primele rînduri indicã cererile fãcute asupra cache-ului, fie cã
ele vin din partea procesorului local, fie dinspre bus, de la masterul
de magistralã; ultimele rînduri indicã reacþia cache-ului.

<P>
În realitate, fiecare cuvînt din cache are un astfel de automat
finit; noi vom arãta cum se comportã automatul finit asociat
cuvîntului din cache care trebuie modificat de tranzacþia curentã.
Pentru a simplifica expunerea, vom desena douã automate finite, unul
care este valabil pentru procesorul master de magistralã, ºi unul
care este valabil pentru celelalte procesoare.  Fiecare procesor va
acþiona dupã una din reguli, depinzînd de starea lui la acel moment
de timp.

<P>
Figura&nbsp;<A HREF="smp-html.html#master">1</A> aratã automatul asociat unui master de
magistralã.  Automatul este destul de complicat, ºi are 10
tranziþii posibile, numerotate în figurã (sunt doar 5 sãgeþi, dar
unele tranziþii folosesc aceeaºi sãgeatã).  Le vom analiza una
cîte una.  Rîndurile albe din tabele indicã faptul cã nu conteazã
ce se aflã acolo, sau cã acolo nu se aflã nimic.

<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="master"></A><A NAME="153"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 1:</STRONG>
Acþiunile unui master de magistralã atunci
cînd procesorul vrea sã opereze asupra blocului x iar în cache se
aflã blocul y.</CAPTION>
<TR><TD><IMG
 WIDTH="541" HEIGHT="452" BORDER="0"
 SRC="img1.png"
 ALT="\begin{figure}\centerline{\epsfxsize=12cm\epsffile{master.eps}}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>
Cititorul care este plictisit de minuþiozitatea detaliilor din desen
ºi text va trebui cu siguranþã sã-ºi caute o meserie înafara
proiectãrii de calculatoare; modelul pe care îl prezentãm aici este
de fapt o simplificare pedagogicã substanþialã; ceea ce se
construieºte în realitate în procesoarele pe care le folosim în
fiecare zi este cu mult mai complicat.  Voi spune cîteva cuvinte mai
jos despre încrederea pe care o putem avea în astfel de design-uri.

<P>
Pe de altã parte uneltele pe care le prezint aici pentru a descrie
comportarea sunt chiar cele folosite de cãtre designerii
profesioniºti: automate finite cu reguli detaliate de tranziþie.

<P>
Iatã explicaþia tranziþiilor, în ordine crescãtoare a
dificultãþii:

<P>
<DL>
<DT><STRONG>Tranziþia numãrul 3:</STRONG></DT>
<DD>Procesorul (linia 1 din tabelul nr. 3)
doreºte sã citeascã (indicat de linia 2) de la adresa x.  Cuvîntul
este prezent în cache (linia 3), ºi este ``curat'' (starea curentã
este ``curat'').  Rezultatul este foarte simplu: nici o acþiune nu este
iniþiatã pe magistralã (liniile 4, 5 sunt goale în tabel);
cuvîntul este imediat servit procesorului, care terminã operaþia de
citire (linia 7).

<P>
</DD>
<DT><STRONG>Tranziþia 8:</STRONG></DT>
<DD>Procesorul doreºte sã citeascã de la adresa x,
care este în cache, ºi este marcatã ``murdarã''.  Citirea se poate
face imediat, fãrã a implica magistrala.

<P>
</DD>
<DT><STRONG>Tranziþia 7:</STRONG></DT>
<DD>Procesorul vrea sã scrie la adresa x, iar
cuvîntul de la adresa x este prezent ºi este deja murdar.  Scrierea
se poate face imediat, fãrã a implica magistrala.

<P>
Primele trei tranziþii descrise mai sus sunt foarte simple, pentru
cã datele sunt imediat disponibile ºi pentru cã nu trebuie recurs
la magistralã.  Iatã acum trei situaþii care se pot rezolva cu
cîte o tranziþie fiecare, dar care au nevoie de magistralã:

<P>
</DD>
<DT><STRONG>Tranziþia 1:</STRONG></DT>
<DD>Procesorul doreºte sã citeascã de la adresa x.
În cache obiectul de la adresa x este marcat ca fiind invalid.  În
cazul asta pe magistralã este lansatã comanda de citire (linia 4 din
tabel) de la adresa x (linia 5).  Modelul nostru presupune cã datele
de la adresa x vor fi trimise imediat de cel care le posedã (memoria
sau un alt cache), deci ele vor fi încãrcate în cache (linia 6);
simultan ele vor fi trimise la procesor, care terminã astfel
operaþia de citire (linia 7).  Pentru cã procesorul are de acum o
copie a valorii, blocul este marcat ca ``curat'' (tranziþie de la
Invalid la Curat).

<P>
</DD>
<DT><STRONG>Tranziþia 4:</STRONG></DT>
<DD>Procesorul vrea sã citeascã x, dar în cache
în acel loc se aflã altceva (linia 3), care este curat.  Pentru cã
acea valoare este curatã, ea este imediat ºtearsã din cache
(existã o copie în memorie), pe bus este pusã o cerere pentru x
(linia 5); presupunem cã x vine imediat.  x este apoi încãrcat în
cache, ºi procesorul terminã citirea.

<P>
</DD>
<DT><STRONG>Tranziþia 6:</STRONG></DT>
<DD>Vreau sã scriu în cuvîntul de la adresa x, am
o copie a lui, dar nu sunt singurul.  Atunci pun o cerere de
invalidare (linia 4) a adresei x (linia 5) pe magistralã; în acest
fel toþi posesorii lui x sunt rugaþi sã-l invalideze (ºtiu cã
nimeni nu are o copie murdarã).  Toatã lumea va reacþiona corect la
aceastã cerere, aºa cã putem modifica valoarea lui x în cache-ul
local.  Valoarea ca atare devine ``murdarã''.

<P>
ªi astea trei situaþii au fost relativ simple, datoritã modelului
nostru care nu foloseºte ``split transaction'' (am presupus cã
datele cerute vin imediat; dacã dureazã mai mulþi cicli, practic
procesorul master ºi bus-ul sunt blocate pînã cînd datele
aºteptate de master ajung la destinaþie).  

<P>
Operaþiile rãmase sunt mult mai încîlcite, ºi cer o <EM>succesiune de mai multe tranziþii pentru a fi îndeplinite</EM>.
Presupunem, din nou pentru a simplifica, cã acelaºi cache rãmînã
master de magistralã pînã terminã operaþia începutã, chiar daca
asta implicã mai multe transferuri pe magistralã.

<P>
Iatã niºte operaþii care cer cîte <EM>douã tranzacþii</EM> pentru a
fi executate (pe bus trebuie sã circule douã valori diferite).
Procesorul master este deci blocat timp de douã operaþii.

<P>
</DD>
<DT><STRONG>Tranziþia 5 (+6):</STRONG></DT>
<DD>Vreau sã scriu în cuvîntul de la x, dar
nu-l am.  Atunci fac doi paºi: întîi obþin o copie a cuvîntului
(tranziþia 5), dupã care continui cu tranzacþia 6, invalidînd
celelalte copii ºi scriind valoarea.  Tranziþia 5 va bloca
procesorul (linia 7) pînã se terminã tranziþia 6 (abia atunci pot
sã fac ceea ce mi s-a cerut).

<P>
</DD>
<DT><STRONG>Tranziþia 9 (+1):</STRONG></DT>
<DD>Vreau sã citesc la adresa x, dar locul e
ocupat de cuvîntul de la y, care e ºi murdar pe deasupra.  Atunci,
în tranziþia 9, pun acest cuvînt pe bus, ºi rog memoria sã-l
copieze.  Blochez procesorul.  Dupã ce am scris cuvîntul, marchez
linia ca invalidã ºi execut tranziþia 1, pentru a citi cuvîntul
cerut.

<P>
</DD>
<DT><STRONG>Tranziþia 2 (+6):</STRONG></DT>
<DD>Vreau sã scriu la adresa x, dar nu am nici
o copie a lui x (e marcatã ``invalidã'').  Atunci în primul rînd
(tranziþia 2) obþin o copie a lui x ca la o citire (linia 4)
obiºnuitã, dupã care pot face scrierea (tranziþia 6).

<P>
În fine, avem o situaþie, cea mai neplãcutã, cînd pentru a face
ceea ce procesorul ne cere, trebuie sã facem nu mai puþin de 3
tranziþii!  Situaþia apare cînd vreau sã scriu într-un cuvînt,
dar am în acel loc un altul murdar.

<P>
</DD>
<DT><STRONG>Tranziþia 10 (+1, +6):</STRONG></DT>
<DD>Încep prin a goli cuvîntul murdar cu
tranziþia 10; marchez linia ``invalidã''.  Apoi fac tranziþia 1,
pentru a obþine o copie ``curatã'', ºi apoi fac tranziþia 6,
pentru a invalida celelalte copii ºi marchez copia curentã ca
murdarã.

<P>
</DD>
</DL>

<P>

<H2><A NAME="SECTION00066000000000000000">
Automatul finit al unui cache non-master</A>
</H2>

<P>
Bravo!  Dacã aþi ajuns pînã aici sunteþi foarte rãbdãtori, sau
aþi sãrit suficient de multe paragrafe.

<P>
Ce-a rãmas este mult mai simplu: descrierea acþiunilor unui cache
``sclav'' (care nu e master de magistralã).  Schema este mult mai
simplã, pentru cã un astfel de cache nu poate folosi de loc
magistrala, cu o singurã excepþie: cînd primeºte o cerere de
citire a unui bloc murdar, în care caz trebuie sã-l punã pe
magistralã pentru master.  Toatã schema este în figura&nbsp;<A HREF="smp-html.html#sclav">2</A>.

<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="sclav"></A><A NAME="159"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 2:</STRONG>
Acþiunile unui sclav.</CAPTION>
<TR><TD><IMG
 WIDTH="541" HEIGHT="373" BORDER="0"
 SRC="img2.png"
 ALT="\begin{figure}\centerline{\epsfxsize=12cm\epsffile{sclav.eps}}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<DL>
<DT><STRONG>Tranziþia 4:</STRONG></DT>
<DD>bus-ul vrea o anumitã adresã pe care nu o avem;
nu facem nimic;

<P>
</DD>
<DT><STRONG>Tranziþia 3:</STRONG></DT>
<DD>bus-ul vrea o adresã pe care o avem, dar care e
curatã; atunci memoria o sã satisfacã aceastã cerere, deci
iarãºi nu facem nimic;

<P>
</DD>
<DT><STRONG>Tranziþia 2:</STRONG></DT>
<DD>bus-ul vrea o adresã pe care nu o am; nu fac
nimic;

<P>
</DD>
<DT><STRONG>Tranziþia 1:</STRONG></DT>
<DD>primesc o cerere de invalidare a unui bloc curat
pe care îl am: atunci marchez blocul ca invalid;

<P>
</DD>
<DT><STRONG>Tranziþia 5:</STRONG></DT>
<DD>bus-ul vrea sã citeascã un bloc pe care îl am
murdar; atunci pun valoarea pe bus, memoria va copia aceastã valoare.
Eu o marchez curatã.
</DD>
</DL>

<P>

<H1><A NAME="SECTION00070000000000000000">
Corectitudine</A>
</H1>

<P>
Perfect; am specificat fiecare acþiune în funcþie de circumstanþe
suficient de detaliat pentru a putea fi implementatã.  Dar cum de
ºtim cã protocolul este corect?

<P>
De pildã poate pãrea ciudat cã în ultima diagramã nu e nici o
sãgeatã din starea ``murdar'' care sã aibã în tabel o invalidare.
Este cumva o omisiune?  Nu, pentru cã aºa cum am proiectat
protocolul, un cache poate lansa o invalidare numai dupã ce are o
copie a datelor, deci ele nu pot fi simultan murdare altundeva.

<P>
Inutil de spus cã verificarea unor sisteme reale este o treabã
extrem de grea; modelul nostru este simplificat într-o mulþime de
privinþe.  Ceea ce e într-un Pentium este de multe ori mai complicat
decît modelul prezentat (Pentium are cache-uri ne-blocante, ºi dacã
procesorul nu primeºte niºte date pe care le-a cerut, el poate cere
altele; datele pot sosi într-o ordine diferitã de cea a cererilor!).

<P>
Marile companii de hardware (ex. Intel, IBM) folosesc pentru a
verifica corectitudinea unor astfel de scheme tot calculatoarele.  Pe
de o parte se folosesc simulãri ºi teste complete: sistemul este
implementat ca un program, care apoi este testat pe toate
combinaþiile posibile de ordini de evenimente care pot apãrea.
Treaba asta este extrem de complicatã, pentru cã numãrul de teste
creºte enorm cu complexitatea circuitului, ajungînd rapid la valori
impractice chiar pentru cele mai performante calculatoare.

<P>
O altã metodã este cea de a folosi scule speciale pentru a verifica
corectitudinea; o ramurã specialã a ºtiinþei calculatoarelor se
numeºte ``model theory'' ºi se ocupã cu metode de a analiza sisteme
finite extrem de complicate folosind ecuaþiile care descriu
traiectoria sistemului.  Un automat finit este o descriere suficient
de precisã pentru a face o analizã exactã posibilã.  Metodele se
bazeazã pe teorii matematice destul de sofisticate, pentru a reduce
substanþial spaþiul cãutãrilor (logici temporale, diagrame binare
de decizie, simulare ºi bisimulare, abstracþie, etc.).  Din pãcate
metodele practice sunt cam cu 10 ani în urma tehnologiei: nici nu se
pune problema de a verifica exhaustiv circuitele contemporane, chiar
ºi cu scule atît de sofisticate.

<P>

<H1><A NAME="SECTION00080000000000000000">
Un exemplu: SGI Challenge</A>
</H1>

<P>
Iatã caracteristicile tehnice ale unei maºini reale care foloseºte
tehnicile prezentate: SGI Challenge; acesta este cel mai mare
multiprocesor bazat pe bus, cu 36 de procesoare MIPS R4400, o
adevãratã minune tehnologicã.

<P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3>
<TR><TD ALIGN="LEFT">Procesoare</TD>
<TD ALIGN="LEFT">pînã la 36</TD>
</TR>
<TR><TD ALIGN="LEFT">Memorie</TD>
<TD ALIGN="LEFT">pînã la 16 Gb</TD>
</TR>
<TR><TD ALIGN="LEFT">Lãþime bus (date)</TD>
<TD ALIGN="LEFT">256 biþi</TD>
</TR>
<TR><TD ALIGN="LEFT">Lãþime bus (adrese)</TD>
<TD ALIGN="LEFT">40 biþi</TD>
</TR>
<TR><TD ALIGN="LEFT">Rata de transfer</TD>
<TD ALIGN="LEFT">1.22 Gb/sec</TD>
</TR>
<TR><TD ALIGN="LEFT">Tranzacþii</TD>
<TD ALIGN="LEFT">model ``split''</TD>
</TR>
<TR><TD ALIGN="LEFT">Frecvenþa magistralei</TD>
<TD ALIGN="LEFT">50Mhz</TD>
</TR>
<TR><TD ALIGN="LEFT">Penalizarea pentru un rateu în cache</TD>
<TD ALIGN="LEFT">&gt 164 cicli</TD>
</TR>
</TABLE>
</DIV>

<P>
Costul unei operaþii care nu gãseºte datele în cache este extrem de
substanþial, datoritã complexitãþii protocoalelor (în <a
href="http://www.cs.cmu.edu/~mihaib/articles/articles.html#masuri">articolul
anterior</a> din PC Report am vãzut ca la un Pentium uniprocesor
durata este de ordinul a 13 cicli de procesor).  Din cauza asta
implementarea unor protocoale de coerenþã eficiente este extrem de
importantã, dar performanþa obþinutã datoritã unui numãr ridicat de
procesoare compenseazã costul ridicat al execuþiei fiecãruia.

<P>
Voi încheia acest articol aici, deºi îmi propusesem sã mai atac
ºi alte subiecte; rezultatul însã pare destul de consistent, aºa
cã o sã amîn pentru alte ocazii discuþii despre subiecte subtile
cum ar fi: alte protocoale de coerenþã, sau impactul modului în
care e implementat un protocol de coerenþã pentru performanþa
anumitor construcþii din programele utilizatorilor.  Vã îndemn sã
studiaþi cu atenþie diagramele de mai sus.  Chiar dacã conceptele
sunt pe alocuri simplificate, scenariile sunt toate plauzibile.  În
definitiv e foarte plãcut sã înþelegi sculele cu care lucrezi, nu?

<P>
<BR><HR><H4>Footnotes</H4>
<DL>
<DT><A NAME="foot51">... faliment</A><A NAME="foot51"
 HREF="smp-html.html#tex2html1"><SUP>1</SUP></A>
<DD>La ora asta
supercalculatoare mai fabricã numai Intel, IBM, Silicon Graphics --
care a cumpãrat în 1987 cea mai celebrã firmã de
supercalculatoare, Cray Research -- Hitachi ºi dacã nu mã înºel
Fujitsu.

</DL>
<BR><HR>

</BODY>
</HTML>
